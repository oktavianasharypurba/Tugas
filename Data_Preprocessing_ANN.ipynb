{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing_ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T8HzK5vJm8y"
      },
      "source": [
        "IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUUyhcTb99PA"
      },
      "source": [
        "#Import library yang dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utrIvcH6JpoF"
      },
      "source": [
        "LOAD DATA SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_rLLA28v-RRd",
        "outputId": "b126a49a-5cd6-407d-d066-77957df0335d"
      },
      "source": [
        "#load dataset\n",
        "data = pd.read_csv('Data_test.csv')\n",
        "data.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>tinggi air</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>4.6</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.3</td>\n",
              "      <td>904.0</td>\n",
              "      <td>47</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>2.1</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>18</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>3.2</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.3</td>\n",
              "      <td>793.0</td>\n",
              "      <td>19</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>1.4</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.4</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.3</td>\n",
              "      <td>977.0</td>\n",
              "      <td>19</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      PH cahaya  ... tinggi air                                  aksi\n",
              "611  4.6    Ada  ...         47                        Hidupkan Lampu\n",
              "612  2.1    Ada  ...         18  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "613  3.2    Ada  ...         19                        Hidupkan Lampu\n",
              "614  1.4    Ada  ...          3                        Hidupkan Lampu\n",
              "615  5.0    Ada  ...         19                        Hidupkan Lampu\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC3eV3aDJ13g"
      },
      "source": [
        "MENGGANTI LABEL BERSPASI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "x5qmWJ83-XeT",
        "outputId": "db5ddc3a-23ac-4fbd-cfda-940f0e656078"
      },
      "source": [
        "data = data.rename(columns={'PH':'pH', 'intensitas air':'intensitas_air', 'tinggi air':'tinggi_air'})\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>tinggi_air</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>622</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>557</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>491</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.5</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>12000</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>444</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>4.6</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.3</td>\n",
              "      <td>904.0</td>\n",
              "      <td>47</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>2.1</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>18</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>3.2</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.3</td>\n",
              "      <td>793.0</td>\n",
              "      <td>19</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>1.4</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.4</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Rendah sekali</td>\n",
              "      <td>25.3</td>\n",
              "      <td>977.0</td>\n",
              "      <td>19</td>\n",
              "      <td>Hidupkan Lampu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>616 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pH cahaya  ... tinggi_air                                  aksi\n",
              "0    6.5    Ada  ...        622  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1    5.7    Ada  ...        557  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2    6.0    Ada  ...        491  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3    6.5    Ada  ...      12000               Tidak melakukan apa-apa\n",
              "4    6.2    NaN  ...        444               Tidak melakukan apa-apa\n",
              "..   ...    ...  ...        ...                                   ...\n",
              "611  4.6    Ada  ...         47                        Hidupkan Lampu\n",
              "612  2.1    Ada  ...         18  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "613  3.2    Ada  ...         19                        Hidupkan Lampu\n",
              "614  1.4    Ada  ...          3                        Hidupkan Lampu\n",
              "615  5.0    Ada  ...         19                        Hidupkan Lampu\n",
              "\n",
              "[616 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyUKGYbH-hzG",
        "outputId": "3e9f15cd-2653-4574-c0c2-6b99fd1f31c1"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 616 entries, 0 to 615\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   pH              600 non-null    float64\n",
            " 1   cahaya          590 non-null    object \n",
            " 2   intensitas_air  616 non-null    object \n",
            " 3   suhu            589 non-null    float64\n",
            " 4   PPM             611 non-null    float64\n",
            " 5   tinggi_air      616 non-null    int64  \n",
            " 6   aksi            616 non-null    object \n",
            "dtypes: float64(3), int64(1), object(3)\n",
            "memory usage: 33.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHdJaNw6-nWq",
        "outputId": "dc5931b1-dca8-4a53-be3e-3c536bade5e6"
      },
      "source": [
        "data['aksi'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tidak melakukan apa-apa                 473\n",
              "Hidupkan Lampu                           92\n",
              "Hidupkan Lampu dan Pompa nutrisi TDS     39\n",
              "Hidupkan Pompa nutrisi TDS               12\n",
              "Name: aksi, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdXhy2yP-o_l",
        "outputId": "fb17d65e-618d-4f88-bf51-e0c98a313c00"
      },
      "source": [
        "data['cahaya'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ada          302\n",
              "Tidak ada    288\n",
              "Name: cahaya, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhACiqIb-up_",
        "outputId": "709603e0-02c4-4eee-afc9-8610a964100a"
      },
      "source": [
        "data['intensitas_air'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rendah           154\n",
              "Cukup            154\n",
              "Rendah sekali    154\n",
              "Tinggi           154\n",
              "Name: intensitas_air, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "GYwnOpOU-yBC",
        "outputId": "a80267f0-6929-411e-8878-b5297412902c"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': data.isnull().sum(), 'perc_missing': (data.isnull().sum()/616)*100})\n",
        "missing_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pH</th>\n",
              "      <td>16</td>\n",
              "      <td>2.597403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cahaya</th>\n",
              "      <td>26</td>\n",
              "      <td>4.220779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intensitas_air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suhu</th>\n",
              "      <td>27</td>\n",
              "      <td>4.383117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPM</th>\n",
              "      <td>5</td>\n",
              "      <td>0.811688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tinggi_air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aksi</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "pH                         16      2.597403\n",
              "cahaya                     26      4.220779\n",
              "intensitas_air              0      0.000000\n",
              "suhu                       27      4.383117\n",
              "PPM                         5      0.811688\n",
              "tinggi_air                  0      0.000000\n",
              "aksi                        0      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "qki6gGox-7u7",
        "outputId": "ba0e8b69-5a43-4187-b134-9c1ea2701731"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>tinggi_air</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>600.000000</td>\n",
              "      <td>589.000000</td>\n",
              "      <td>611.000000</td>\n",
              "      <td>616.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.655167</td>\n",
              "      <td>29.364007</td>\n",
              "      <td>1032.836334</td>\n",
              "      <td>288.173701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.043234</td>\n",
              "      <td>14.937524</td>\n",
              "      <td>632.614766</td>\n",
              "      <td>622.457710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.500000</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>487.500000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.500000</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>991.000000</td>\n",
              "      <td>230.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>1603.500000</td>\n",
              "      <td>429.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>2149.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               pH        suhu          PPM    tinggi_air\n",
              "count  600.000000  589.000000   611.000000    616.000000\n",
              "mean     6.655167   29.364007  1032.836334    288.173701\n",
              "std      3.043234   14.937524   632.614766    622.457710\n",
              "min      0.000000 -300.000000     1.000000      0.000000\n",
              "25%      5.500000   27.100000   487.500000     50.000000\n",
              "50%      6.500000   29.900000   991.000000    230.000000\n",
              "75%      7.700000   33.000000  1603.500000    429.500000\n",
              "max     14.000000   40.600000  2149.000000  12000.000000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6qopZ6bb_Aac",
        "outputId": "92fe0681-fee8-4dbf-9945-e98481856697"
      },
      "source": [
        "del data[\"tinggi_air\"]\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.5</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pH cahaya intensitas_air  suhu    PPM                                  aksi\n",
              "0  6.5    Ada         Tinggi  27.0  188.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1  5.7    Ada         Tinggi  26.9   79.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2  6.0    Ada         Tinggi  27.0   11.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3  6.5    Ada         Tinggi  27.1  345.0               Tidak melakukan apa-apa\n",
              "4  6.2    NaN         Tinggi  27.1  602.0               Tidak melakukan apa-apa"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "aYRBWCaY_FKG",
        "outputId": "e84194aa-d31b-4935-a91a-0e35e1442330"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': data.isnull().sum(), 'perc_missing': (data.isnull().sum()/616)*100})\n",
        "missing_data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pH</th>\n",
              "      <td>16</td>\n",
              "      <td>2.597403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cahaya</th>\n",
              "      <td>26</td>\n",
              "      <td>4.220779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intensitas_air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suhu</th>\n",
              "      <td>27</td>\n",
              "      <td>4.383117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPM</th>\n",
              "      <td>5</td>\n",
              "      <td>0.811688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aksi</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "pH                         16      2.597403\n",
              "cahaya                     26      4.220779\n",
              "intensitas_air              0      0.000000\n",
              "suhu                       27      4.383117\n",
              "PPM                         5      0.811688\n",
              "aksi                        0      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vTmSPDWw_gy-",
        "outputId": "43fb63f9-5561-4fb5-8bd6-44118de2b023"
      },
      "source": [
        "def getNumber(str):\n",
        "    if str==\"Ada\":\n",
        "        return 1\n",
        "    elif str==\"Tidak ada\":\n",
        "        return 0\n",
        "    else:\n",
        "        return str\n",
        "\n",
        "data[\"cahaya\"] = data[\"cahaya\"].apply(getNumber)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pH  cahaya  ...    PPM                                  aksi\n",
              "0  6.5     1.0  ...  188.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1  5.7     1.0  ...   79.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2  6.0     1.0  ...   11.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3  6.5     1.0  ...  345.0               Tidak melakukan apa-apa\n",
              "4  6.2     NaN  ...  602.0               Tidak melakukan apa-apa\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "U9y8O0x-A3qp",
        "outputId": "ef564ef7-b09e-454a-bbf7-b1cf59cab5c7"
      },
      "source": [
        "def getNumber(str):\n",
        "    if str==\"Tidak melakukan apa-apa\":\n",
        "        return 3\n",
        "    elif str==\"Hidupkan Lampu\":\n",
        "        return 2\n",
        "    elif str==\"Hidupkan Lampu dan Pompa nutrisi TDS\":\n",
        "        return 1\n",
        "    elif str==\"Hidupkan Pompa nutrisi TDS\":\n",
        "        return 0\n",
        "    else:\n",
        "        return str\n",
        "\n",
        "data[\"aksi\"] = data[\"aksi\"].apply(getNumber)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pH  cahaya intensitas_air  suhu    PPM  aksi\n",
              "0  6.5     1.0         Tinggi  27.0  188.0     1\n",
              "1  5.7     1.0         Tinggi  26.9   79.0     1\n",
              "2  6.0     1.0         Tinggi  27.0   11.0     1\n",
              "3  6.5     1.0         Tinggi  27.1  345.0     3\n",
              "4  6.2     NaN         Tinggi  27.1  602.0     3"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bauDBxnsBAsD",
        "outputId": "b6e59b47-402a-4738-ae16-51f650400ed9"
      },
      "source": [
        "def getNumber(str):\n",
        "    if str==\"Rendah\":\n",
        "        return 3\n",
        "    elif str==\"Cukup\":\n",
        "        return 2\n",
        "    elif str==\"Tinggi\":\n",
        "        return 1\n",
        "    elif str==\"Rendah sekali\":\n",
        "        return 0\n",
        "    else:\n",
        "        return str\n",
        "\n",
        "data[\"intensitas_air\"] = data[\"intensitas_air\"].apply(getNumber)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pH  cahaya  intensitas_air  suhu    PPM  aksi\n",
              "0  6.5     1.0               1  27.0  188.0     1\n",
              "1  5.7     1.0               1  26.9   79.0     1\n",
              "2  6.0     1.0               1  27.0   11.0     1\n",
              "3  6.5     1.0               1  27.1  345.0     3\n",
              "4  6.2     NaN               1  27.1  602.0     3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "o7bB5sQmCak1",
        "outputId": "0685263d-2e16-4d5c-dea9-ae8c85d5aa0f"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': data.isnull().sum(), 'perc_missing': (data.isnull().sum()/616)*100})\n",
        "missing_data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pH</th>\n",
              "      <td>16</td>\n",
              "      <td>2.597403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cahaya</th>\n",
              "      <td>26</td>\n",
              "      <td>4.220779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intensitas_air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suhu</th>\n",
              "      <td>27</td>\n",
              "      <td>4.383117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPM</th>\n",
              "      <td>5</td>\n",
              "      <td>0.811688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aksi</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "pH                         16      2.597403\n",
              "cahaya                     26      4.220779\n",
              "intensitas_air              0      0.000000\n",
              "suhu                       27      4.383117\n",
              "PPM                         5      0.811688\n",
              "aksi                        0      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVBPQQjXCmqx",
        "outputId": "fb05cb09-5e52-461d-afd0-6cfec3b5704a"
      },
      "source": [
        "#Mengelompokkan missing value\n",
        "column_missing = ['pH', 'cahaya', 'suhu', 'PPM']\n",
        "column_missing"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pH', 'cahaya', 'suhu', 'PPM']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5myycE6yC0H1",
        "outputId": "30f68211-78e7-4c91-a201-be45840e2e26"
      },
      "source": [
        "#Solve Missing value\n",
        "for col in column_missing:\n",
        "  data[col].replace(np.nan, data[col].mean(), inplace=True)\n",
        "\n",
        "data.isnull().sum()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pH                0\n",
              "cahaya            0\n",
              "intensitas_air    0\n",
              "suhu              0\n",
              "PPM               0\n",
              "aksi              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGynxK-9DCcV",
        "outputId": "665211dc-8ba2-4d2c-ed02-c13344e7e1a8"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pH', 'cahaya', 'intensitas_air', 'suhu', 'PPM', 'aksi'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "y2uSvkT2DFlK",
        "outputId": "44a315f0-da84-4083-acd0-df942a5a5ce1"
      },
      "source": [
        "num_col = ['pH', 'cahaya', 'intensitas_air', 'suhu', 'PPM', 'aksi']\n",
        "plt.figure(figsize=(19,9))\n",
        "data[num_col].boxplot()\n",
        "plt.title(\"Numerical Variables in Water Quality data set\", fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1368x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPhcgtm5KC2c"
      },
      "source": [
        "MEMISAHKAN FEATURE DAN LABEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuyIOs90DMLU",
        "outputId": "0d2ff1e8-91b7-45e7-8db0-10bc26e39c99"
      },
      "source": [
        "#definisi x\n",
        "X = data.iloc[:,:5].values\n",
        "X"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.500e+00, 1.000e+00, 1.000e+00, 2.700e+01, 1.880e+02],\n",
              "       [5.700e+00, 1.000e+00, 1.000e+00, 2.690e+01, 7.900e+01],\n",
              "       [6.000e+00, 1.000e+00, 1.000e+00, 2.700e+01, 1.100e+01],\n",
              "       ...,\n",
              "       [3.200e+00, 1.000e+00, 0.000e+00, 2.530e+01, 7.930e+02],\n",
              "       [1.400e+00, 1.000e+00, 0.000e+00, 2.540e+01, 1.052e+03],\n",
              "       [5.000e+00, 1.000e+00, 0.000e+00, 2.530e+01, 9.770e+02]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pyIXxaIDZSJ",
        "outputId": "f7fbfe77-65ae-4383-f730-ee56342500ba"
      },
      "source": [
        "#definisi y\n",
        "Y = data.iloc[:, 5].values \n",
        "Y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
              "       2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 1, 3, 1, 1, 1, 3, 1, 3, 3, 3, 2, 2,\n",
              "       3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3,\n",
              "       3, 1, 3, 1, 3, 1, 1, 3, 3, 2, 3, 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3,\n",
              "       3, 3, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
              "       2, 2, 3, 3, 2, 1, 2, 3, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1,\n",
              "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byeQDEdDDbwE",
        "outputId": "a77d95b5-2ef9-4b41-e704-69951599cc06"
      },
      "source": [
        "counter = Counter(Y) #Check Balance data\n",
        "print(counter)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({3: 473, 2: 92, 1: 39, 0: 12})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJELTTeZDkBu"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(k_neighbors=5)\n",
        "X_smote, Y_smote = oversample.fit_resample(X, Y)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiKVcfF6DoIF",
        "outputId": "0bd05e96-c997-420c-875f-aa95fe260345"
      },
      "source": [
        "counter = Counter(Y_smote)\n",
        "print(counter)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 473, 3: 473, 2: 473, 0: 473})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsT03ILKTNR"
      },
      "source": [
        "MELAKUKAN NORMALISASI DATA DENGAN MIN MAX SCALER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8lekXWoEnmw",
        "outputId": "4f968a21-f5b1-404d-964a-018eef8ca02a"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler =  MinMaxScaler()\n",
        "# transform data\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.46428571 1.         0.33333333 0.96007046 0.08705773]\n",
            " [0.40714286 1.         0.33333333 0.95977686 0.03631285]\n",
            " [0.42857143 1.         0.33333333 0.96007046 0.00465549]\n",
            " ...\n",
            " [0.22857143 1.         0.         0.95507927 0.36871508]\n",
            " [0.1        1.         0.         0.95537287 0.48929236]\n",
            " [0.35714286 1.         0.         0.95507927 0.45437616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLxVA6FgEutk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X_scaled, Y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "#membagi data test dan validation\n",
        "(X_train, X_valid) = X_train[148:], X_train[:148]\n",
        "(Y_train, Y_valid) = Y_train[148:], Y_train[:148]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvtnR2irKc5F"
      },
      "source": [
        "ANN METHOD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nck5ZmK2EzQi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, activation='relu')) #Input Layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(11, activation='relu')) #Hidden Layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(7, activation='relu')) #Hidden Layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1))#Output Layer"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI_MwYf3E3vm",
        "outputId": "20d3bdd6-7f61-44c4-d59a-719b5128121a"
      },
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "\n",
        "predict = model.fit(X_train, Y_train, epochs=2000, batch_size=8, validation_data=(X_valid, Y_valid)) #Training Model "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "43/43 [==============================] - 2s 8ms/step - loss: 2.6379 - val_loss: 2.2207\n",
            "Epoch 2/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.4509 - val_loss: 1.7766\n",
            "Epoch 3/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.2939 - val_loss: 1.5198\n",
            "Epoch 4/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 2.1000 - val_loss: 1.2741\n",
            "Epoch 5/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.8497 - val_loss: 1.0208\n",
            "Epoch 6/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.6746 - val_loss: 0.8400\n",
            "Epoch 7/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5356 - val_loss: 0.7442\n",
            "Epoch 8/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.2617 - val_loss: 0.6384\n",
            "Epoch 9/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.1454 - val_loss: 0.5959\n",
            "Epoch 10/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.0148 - val_loss: 0.5469\n",
            "Epoch 11/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.9821 - val_loss: 0.5158\n",
            "Epoch 12/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.8955 - val_loss: 0.5039\n",
            "Epoch 13/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7190 - val_loss: 0.4980\n",
            "Epoch 14/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6709 - val_loss: 0.4890\n",
            "Epoch 15/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7213 - val_loss: 0.4618\n",
            "Epoch 16/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7255 - val_loss: 0.4726\n",
            "Epoch 17/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6832 - val_loss: 0.4753\n",
            "Epoch 18/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6548 - val_loss: 0.4529\n",
            "Epoch 19/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6396 - val_loss: 0.4444\n",
            "Epoch 20/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6068 - val_loss: 0.4379\n",
            "Epoch 21/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.4362\n",
            "Epoch 22/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5751 - val_loss: 0.4336\n",
            "Epoch 23/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.4281\n",
            "Epoch 24/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 0.4291\n",
            "Epoch 25/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.4217\n",
            "Epoch 26/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.5198 - val_loss: 0.4178\n",
            "Epoch 27/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.4148\n",
            "Epoch 28/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.4131\n",
            "Epoch 29/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4846 - val_loss: 0.4100\n",
            "Epoch 30/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4525 - val_loss: 0.4042\n",
            "Epoch 31/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4491 - val_loss: 0.4012\n",
            "Epoch 32/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 0.3988\n",
            "Epoch 33/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.3974\n",
            "Epoch 34/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.3861\n",
            "Epoch 35/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.3866\n",
            "Epoch 36/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.3746\n",
            "Epoch 37/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4254 - val_loss: 0.3843\n",
            "Epoch 38/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4201 - val_loss: 0.3777\n",
            "Epoch 39/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.3893\n",
            "Epoch 40/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.3856\n",
            "Epoch 41/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.3851\n",
            "Epoch 42/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.3833\n",
            "Epoch 43/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3811\n",
            "Epoch 44/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.3782\n",
            "Epoch 45/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3691 - val_loss: 0.3795\n",
            "Epoch 46/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.3754\n",
            "Epoch 47/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3544 - val_loss: 0.3776\n",
            "Epoch 48/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3562 - val_loss: 0.3792\n",
            "Epoch 49/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3535 - val_loss: 0.3748\n",
            "Epoch 50/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.3775\n",
            "Epoch 51/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3805\n",
            "Epoch 52/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.3751\n",
            "Epoch 53/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.3771\n",
            "Epoch 54/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.3767\n",
            "Epoch 55/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.3730\n",
            "Epoch 56/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3723\n",
            "Epoch 57/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3753\n",
            "Epoch 58/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3251 - val_loss: 0.3721\n",
            "Epoch 59/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3222 - val_loss: 0.3706\n",
            "Epoch 60/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3208 - val_loss: 0.3705\n",
            "Epoch 61/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.3727\n",
            "Epoch 62/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3194 - val_loss: 0.3727\n",
            "Epoch 63/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3134 - val_loss: 0.3722\n",
            "Epoch 64/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3143 - val_loss: 0.3690\n",
            "Epoch 65/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3131 - val_loss: 0.3693\n",
            "Epoch 66/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3158 - val_loss: 0.3753\n",
            "Epoch 67/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 0.3683\n",
            "Epoch 68/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3677\n",
            "Epoch 69/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.3696\n",
            "Epoch 70/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3090 - val_loss: 0.3690\n",
            "Epoch 71/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.3670\n",
            "Epoch 72/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3081 - val_loss: 0.3676\n",
            "Epoch 73/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3679\n",
            "Epoch 74/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3062 - val_loss: 0.3666\n",
            "Epoch 75/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3041 - val_loss: 0.3668\n",
            "Epoch 76/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3032 - val_loss: 0.3675\n",
            "Epoch 77/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3049 - val_loss: 0.3670\n",
            "Epoch 78/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3048 - val_loss: 0.3667\n",
            "Epoch 79/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3034 - val_loss: 0.3661\n",
            "Epoch 80/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3654\n",
            "Epoch 81/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3657\n",
            "Epoch 82/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3686\n",
            "Epoch 83/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3021 - val_loss: 0.3662\n",
            "Epoch 84/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3018 - val_loss: 0.3656\n",
            "Epoch 85/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3670\n",
            "Epoch 86/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3659\n",
            "Epoch 87/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3016 - val_loss: 0.3653\n",
            "Epoch 88/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3653\n",
            "Epoch 89/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3663\n",
            "Epoch 90/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3657\n",
            "Epoch 91/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3661\n",
            "Epoch 92/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3654\n",
            "Epoch 93/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3670\n",
            "Epoch 94/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3657\n",
            "Epoch 95/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3671\n",
            "Epoch 96/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3664\n",
            "Epoch 97/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 98/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 99/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3664\n",
            "Epoch 100/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3655\n",
            "Epoch 101/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3664\n",
            "Epoch 102/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 103/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3661\n",
            "Epoch 104/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3670\n",
            "Epoch 105/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3676\n",
            "Epoch 106/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3661\n",
            "Epoch 107/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 108/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3653\n",
            "Epoch 109/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 110/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3651\n",
            "Epoch 111/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 112/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 113/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 114/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 115/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3658\n",
            "Epoch 116/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3659\n",
            "Epoch 117/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3659\n",
            "Epoch 118/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 119/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 120/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 121/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 122/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3672\n",
            "Epoch 123/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 124/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3669\n",
            "Epoch 125/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3662\n",
            "Epoch 126/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 127/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 128/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3663\n",
            "Epoch 129/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3660\n",
            "Epoch 130/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3651\n",
            "Epoch 131/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3654\n",
            "Epoch 132/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3660\n",
            "Epoch 133/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 134/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 135/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 136/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3661\n",
            "Epoch 137/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3660\n",
            "Epoch 138/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 139/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3650\n",
            "Epoch 140/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3663\n",
            "Epoch 141/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 142/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 143/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3662\n",
            "Epoch 144/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 145/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3654\n",
            "Epoch 146/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3663\n",
            "Epoch 147/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3661\n",
            "Epoch 148/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3663\n",
            "Epoch 149/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3669\n",
            "Epoch 150/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3670\n",
            "Epoch 151/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3664\n",
            "Epoch 152/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3660\n",
            "Epoch 153/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 154/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3666\n",
            "Epoch 155/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3662\n",
            "Epoch 156/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3660\n",
            "Epoch 157/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 158/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3656\n",
            "Epoch 159/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 160/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3675\n",
            "Epoch 161/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3656\n",
            "Epoch 162/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 163/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 164/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 165/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3669\n",
            "Epoch 166/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3664\n",
            "Epoch 167/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3659\n",
            "Epoch 168/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3662\n",
            "Epoch 169/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3672\n",
            "Epoch 170/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3654\n",
            "Epoch 171/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3672\n",
            "Epoch 172/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3660\n",
            "Epoch 173/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3668\n",
            "Epoch 174/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3669\n",
            "Epoch 175/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 176/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3653\n",
            "Epoch 177/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 178/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 179/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3659\n",
            "Epoch 180/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3662\n",
            "Epoch 181/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3651\n",
            "Epoch 182/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3658\n",
            "Epoch 183/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3653\n",
            "Epoch 184/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3673\n",
            "Epoch 185/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3667\n",
            "Epoch 186/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 187/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3664\n",
            "Epoch 188/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3660\n",
            "Epoch 189/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3673\n",
            "Epoch 190/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3655\n",
            "Epoch 191/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 192/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 193/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3663\n",
            "Epoch 194/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 195/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3664\n",
            "Epoch 196/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3657\n",
            "Epoch 197/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3666\n",
            "Epoch 198/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 199/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 200/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 201/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3677\n",
            "Epoch 202/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3668\n",
            "Epoch 203/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3668\n",
            "Epoch 204/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3655\n",
            "Epoch 205/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3651\n",
            "Epoch 206/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 207/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 208/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3661\n",
            "Epoch 209/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 210/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3662\n",
            "Epoch 211/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3670\n",
            "Epoch 212/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3652\n",
            "Epoch 213/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 214/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 215/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3677\n",
            "Epoch 216/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.3652\n",
            "Epoch 217/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 218/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 219/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 220/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 221/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 222/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 223/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 224/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 225/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 226/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3661\n",
            "Epoch 227/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3657\n",
            "Epoch 228/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3660\n",
            "Epoch 229/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3668\n",
            "Epoch 230/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3655\n",
            "Epoch 231/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3672\n",
            "Epoch 232/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3655\n",
            "Epoch 233/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3662\n",
            "Epoch 234/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3656\n",
            "Epoch 235/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 236/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 237/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 238/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3663\n",
            "Epoch 239/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3668\n",
            "Epoch 240/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 241/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 242/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3667\n",
            "Epoch 243/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3660\n",
            "Epoch 244/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 245/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3659\n",
            "Epoch 246/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3663\n",
            "Epoch 247/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 248/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 249/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 250/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3655\n",
            "Epoch 251/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3661\n",
            "Epoch 252/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3659\n",
            "Epoch 253/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3678\n",
            "Epoch 254/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3661\n",
            "Epoch 255/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 256/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 257/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 258/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3675\n",
            "Epoch 259/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3653\n",
            "Epoch 260/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 261/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 262/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3662\n",
            "Epoch 263/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3660\n",
            "Epoch 264/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3655\n",
            "Epoch 265/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 266/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 267/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 268/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 269/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 270/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3669\n",
            "Epoch 271/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 0.3669\n",
            "Epoch 272/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 273/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 274/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3671\n",
            "Epoch 275/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 276/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 277/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3653\n",
            "Epoch 278/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3663\n",
            "Epoch 279/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 280/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3657\n",
            "Epoch 281/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3664\n",
            "Epoch 282/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 283/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 284/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3662\n",
            "Epoch 285/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3667\n",
            "Epoch 286/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 287/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 288/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 289/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3666\n",
            "Epoch 290/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3654\n",
            "Epoch 291/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 292/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3670\n",
            "Epoch 293/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3675\n",
            "Epoch 294/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3658\n",
            "Epoch 295/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3663\n",
            "Epoch 296/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 297/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 298/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3662\n",
            "Epoch 299/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3666\n",
            "Epoch 300/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3673\n",
            "Epoch 301/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3018 - val_loss: 0.3666\n",
            "Epoch 302/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 303/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3660\n",
            "Epoch 304/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 305/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 306/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 307/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3667\n",
            "Epoch 308/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3666\n",
            "Epoch 309/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3654\n",
            "Epoch 310/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 311/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3668\n",
            "Epoch 312/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3657\n",
            "Epoch 313/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 314/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3697\n",
            "Epoch 315/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 0.3652\n",
            "Epoch 316/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3663\n",
            "Epoch 317/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 318/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3654\n",
            "Epoch 319/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3655\n",
            "Epoch 320/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 321/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3686\n",
            "Epoch 322/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3664\n",
            "Epoch 323/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3660\n",
            "Epoch 324/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3667\n",
            "Epoch 325/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3674\n",
            "Epoch 326/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3654\n",
            "Epoch 327/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3678\n",
            "Epoch 328/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3678\n",
            "Epoch 329/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3658\n",
            "Epoch 330/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 331/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3664\n",
            "Epoch 332/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3666\n",
            "Epoch 333/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 334/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 335/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3660\n",
            "Epoch 336/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3656\n",
            "Epoch 337/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 338/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3659\n",
            "Epoch 339/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3666\n",
            "Epoch 340/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 341/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 342/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3666\n",
            "Epoch 343/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 344/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3653\n",
            "Epoch 345/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 346/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 347/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3660\n",
            "Epoch 348/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 349/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3664\n",
            "Epoch 350/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 351/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3658\n",
            "Epoch 352/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3653\n",
            "Epoch 353/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3665\n",
            "Epoch 354/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 355/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3662\n",
            "Epoch 356/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3662\n",
            "Epoch 357/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3667\n",
            "Epoch 358/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3659\n",
            "Epoch 359/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 360/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3651\n",
            "Epoch 361/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 362/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3666\n",
            "Epoch 363/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 364/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 365/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 366/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3676\n",
            "Epoch 367/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3661\n",
            "Epoch 368/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 369/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3686\n",
            "Epoch 370/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3713\n",
            "Epoch 371/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3026 - val_loss: 0.3678\n",
            "Epoch 372/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3651\n",
            "Epoch 373/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3675\n",
            "Epoch 374/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3665\n",
            "Epoch 375/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3656\n",
            "Epoch 376/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3663\n",
            "Epoch 377/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3668\n",
            "Epoch 378/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3658\n",
            "Epoch 379/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3664\n",
            "Epoch 380/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3676\n",
            "Epoch 381/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3651\n",
            "Epoch 382/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 383/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3678\n",
            "Epoch 384/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3660\n",
            "Epoch 385/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3652\n",
            "Epoch 386/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3666\n",
            "Epoch 387/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 388/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3659\n",
            "Epoch 389/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 390/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3681\n",
            "Epoch 391/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3667\n",
            "Epoch 392/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3652\n",
            "Epoch 393/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 394/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 395/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3660\n",
            "Epoch 396/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 397/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3669\n",
            "Epoch 398/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 399/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3671\n",
            "Epoch 400/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3024 - val_loss: 0.3655\n",
            "Epoch 401/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 402/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 403/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 404/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3667\n",
            "Epoch 405/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 406/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 407/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 408/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3664\n",
            "Epoch 409/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3663\n",
            "Epoch 410/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 411/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3683\n",
            "Epoch 412/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3654\n",
            "Epoch 413/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3659\n",
            "Epoch 414/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3659\n",
            "Epoch 415/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3021 - val_loss: 0.3659\n",
            "Epoch 416/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3680\n",
            "Epoch 417/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3670\n",
            "Epoch 418/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3659\n",
            "Epoch 419/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 420/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.3650\n",
            "Epoch 421/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3660\n",
            "Epoch 422/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3673\n",
            "Epoch 423/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3664\n",
            "Epoch 424/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3656\n",
            "Epoch 425/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3670\n",
            "Epoch 426/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 427/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3675\n",
            "Epoch 428/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3676\n",
            "Epoch 429/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3024 - val_loss: 0.3707\n",
            "Epoch 430/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3651\n",
            "Epoch 431/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3650\n",
            "Epoch 432/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 433/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3673\n",
            "Epoch 434/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 435/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3666\n",
            "Epoch 436/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 437/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3673\n",
            "Epoch 438/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3664\n",
            "Epoch 439/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 440/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3674\n",
            "Epoch 441/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3649\n",
            "Epoch 442/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 443/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3650\n",
            "Epoch 444/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 445/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 446/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3665\n",
            "Epoch 447/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 448/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.3652\n",
            "Epoch 449/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 450/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3671\n",
            "Epoch 451/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 452/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 453/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3683\n",
            "Epoch 454/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3687\n",
            "Epoch 455/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3666\n",
            "Epoch 456/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 457/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 458/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 459/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3664\n",
            "Epoch 460/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3675\n",
            "Epoch 461/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3651\n",
            "Epoch 462/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3655\n",
            "Epoch 463/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3674\n",
            "Epoch 464/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 465/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3669\n",
            "Epoch 466/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 467/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3675\n",
            "Epoch 468/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 469/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3677\n",
            "Epoch 470/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3664\n",
            "Epoch 471/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 472/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 473/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 474/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3677\n",
            "Epoch 475/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3653\n",
            "Epoch 476/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3025 - val_loss: 0.3685\n",
            "Epoch 477/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3669\n",
            "Epoch 478/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3653\n",
            "Epoch 479/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3664\n",
            "Epoch 480/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3672\n",
            "Epoch 481/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 482/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3660\n",
            "Epoch 483/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3649\n",
            "Epoch 484/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3655\n",
            "Epoch 485/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 486/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 487/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 488/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3672\n",
            "Epoch 489/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3661\n",
            "Epoch 490/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 491/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3665\n",
            "Epoch 492/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 493/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 494/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3668\n",
            "Epoch 495/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3672\n",
            "Epoch 496/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3683\n",
            "Epoch 497/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3663\n",
            "Epoch 498/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 499/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 500/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 501/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3667\n",
            "Epoch 502/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3651\n",
            "Epoch 503/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3649\n",
            "Epoch 504/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3661\n",
            "Epoch 505/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 506/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3683\n",
            "Epoch 507/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 508/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 509/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3677\n",
            "Epoch 510/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3680\n",
            "Epoch 511/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3653\n",
            "Epoch 512/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3665\n",
            "Epoch 513/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 514/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 515/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3666\n",
            "Epoch 516/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3650\n",
            "Epoch 517/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 518/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 519/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 520/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3670\n",
            "Epoch 521/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3649\n",
            "Epoch 522/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3676\n",
            "Epoch 523/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3654\n",
            "Epoch 524/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3650\n",
            "Epoch 525/2000\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.3664\n",
            "Epoch 526/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 527/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3671\n",
            "Epoch 528/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 529/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 530/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3651\n",
            "Epoch 531/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 532/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3667\n",
            "Epoch 533/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 534/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 535/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 536/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 537/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3684\n",
            "Epoch 538/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3662\n",
            "Epoch 539/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 540/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3655\n",
            "Epoch 541/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 542/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 543/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 544/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.3683\n",
            "Epoch 545/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3653\n",
            "Epoch 546/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3663\n",
            "Epoch 547/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 548/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 549/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3669\n",
            "Epoch 550/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 551/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 552/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 553/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 554/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3668\n",
            "Epoch 555/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3673\n",
            "Epoch 556/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3656\n",
            "Epoch 557/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3663\n",
            "Epoch 558/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3649\n",
            "Epoch 559/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 560/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 561/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3660\n",
            "Epoch 562/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 563/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 564/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 565/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3654\n",
            "Epoch 566/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3672\n",
            "Epoch 567/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3666\n",
            "Epoch 568/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3660\n",
            "Epoch 569/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 570/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 571/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 572/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3651\n",
            "Epoch 573/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 574/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3657\n",
            "Epoch 575/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 576/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3674\n",
            "Epoch 577/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 578/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 579/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 580/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3679\n",
            "Epoch 581/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3665\n",
            "Epoch 582/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 583/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3658\n",
            "Epoch 584/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 585/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3696\n",
            "Epoch 586/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3666\n",
            "Epoch 587/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3652\n",
            "Epoch 588/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 589/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 590/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 591/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3670\n",
            "Epoch 592/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 593/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 594/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3659\n",
            "Epoch 595/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3672\n",
            "Epoch 596/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 597/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3657\n",
            "Epoch 598/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 599/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 600/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3651\n",
            "Epoch 601/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 602/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3666\n",
            "Epoch 603/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 604/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 605/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3012 - val_loss: 0.3654\n",
            "Epoch 606/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 607/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3650\n",
            "Epoch 608/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3666\n",
            "Epoch 609/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 610/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3665\n",
            "Epoch 611/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3666\n",
            "Epoch 612/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 613/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 614/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 615/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 616/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3662\n",
            "Epoch 617/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 618/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 619/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3649\n",
            "Epoch 620/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 621/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 622/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3663\n",
            "Epoch 623/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3659\n",
            "Epoch 624/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3665\n",
            "Epoch 625/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 626/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 627/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 628/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 629/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3662\n",
            "Epoch 630/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3664\n",
            "Epoch 631/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 632/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 633/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 634/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 635/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 636/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 637/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 638/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3663\n",
            "Epoch 639/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3660\n",
            "Epoch 640/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 641/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 642/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3659\n",
            "Epoch 643/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3665\n",
            "Epoch 644/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3671\n",
            "Epoch 645/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 646/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 647/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 648/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3667\n",
            "Epoch 649/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 650/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3668\n",
            "Epoch 651/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3651\n",
            "Epoch 652/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 653/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3651\n",
            "Epoch 654/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 655/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 656/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 657/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3670\n",
            "Epoch 658/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 659/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3677\n",
            "Epoch 660/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 661/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3665\n",
            "Epoch 662/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3649\n",
            "Epoch 663/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 664/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3665\n",
            "Epoch 665/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 666/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 667/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 668/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 669/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 670/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 671/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3658\n",
            "Epoch 672/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 673/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3674\n",
            "Epoch 674/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3650\n",
            "Epoch 675/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 676/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3654\n",
            "Epoch 677/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 678/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 679/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3661\n",
            "Epoch 680/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 681/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 682/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 683/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3659\n",
            "Epoch 684/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 685/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 686/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 687/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3649\n",
            "Epoch 688/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 689/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3661\n",
            "Epoch 690/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3015 - val_loss: 0.3650\n",
            "Epoch 691/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 692/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 693/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 694/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 695/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 696/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 697/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 698/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 699/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 700/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3671\n",
            "Epoch 701/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3653\n",
            "Epoch 702/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3654\n",
            "Epoch 703/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 704/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3662\n",
            "Epoch 705/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3649\n",
            "Epoch 706/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3661\n",
            "Epoch 707/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 708/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 709/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 710/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 711/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3669\n",
            "Epoch 712/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 713/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 714/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3654\n",
            "Epoch 715/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3676\n",
            "Epoch 716/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 717/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3676\n",
            "Epoch 718/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3649\n",
            "Epoch 719/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 720/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 721/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 722/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3672\n",
            "Epoch 723/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 724/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3660\n",
            "Epoch 725/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 726/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3661\n",
            "Epoch 727/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 728/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 729/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3665\n",
            "Epoch 730/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3655\n",
            "Epoch 731/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3671\n",
            "Epoch 732/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3649\n",
            "Epoch 733/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 734/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 735/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3666\n",
            "Epoch 736/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 737/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3672\n",
            "Epoch 738/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 739/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3656\n",
            "Epoch 740/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 741/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 742/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3672\n",
            "Epoch 743/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3670\n",
            "Epoch 744/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 745/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 746/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 747/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 748/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3669\n",
            "Epoch 749/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3652\n",
            "Epoch 750/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3655\n",
            "Epoch 751/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 752/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3661\n",
            "Epoch 753/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3674\n",
            "Epoch 754/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3653\n",
            "Epoch 755/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3669\n",
            "Epoch 756/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3664\n",
            "Epoch 757/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 758/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 759/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 760/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 761/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3660\n",
            "Epoch 762/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3668\n",
            "Epoch 763/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 764/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 765/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 766/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3662\n",
            "Epoch 767/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3661\n",
            "Epoch 768/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 769/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 770/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3662\n",
            "Epoch 771/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 772/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3662\n",
            "Epoch 773/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 774/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 775/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 776/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 777/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3660\n",
            "Epoch 778/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 779/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3666\n",
            "Epoch 780/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3650\n",
            "Epoch 781/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3666\n",
            "Epoch 782/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 783/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 784/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 785/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 786/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 787/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 788/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3649\n",
            "Epoch 789/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 790/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3666\n",
            "Epoch 791/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 792/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3664\n",
            "Epoch 793/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 794/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 795/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 796/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3655\n",
            "Epoch 797/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 798/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3649\n",
            "Epoch 799/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 800/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 801/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 802/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 803/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 804/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 805/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3661\n",
            "Epoch 806/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3671\n",
            "Epoch 807/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3651\n",
            "Epoch 808/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 809/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 810/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3666\n",
            "Epoch 811/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 812/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3658\n",
            "Epoch 813/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 814/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 815/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 816/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3662\n",
            "Epoch 817/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3660\n",
            "Epoch 818/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 819/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3669\n",
            "Epoch 820/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 821/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 822/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 823/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 824/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3663\n",
            "Epoch 825/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 826/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 827/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 828/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 829/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 830/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 831/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 832/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 833/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3672\n",
            "Epoch 834/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3664\n",
            "Epoch 835/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3650\n",
            "Epoch 836/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3651\n",
            "Epoch 837/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 838/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 839/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 840/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3668\n",
            "Epoch 841/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3664\n",
            "Epoch 842/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3662\n",
            "Epoch 843/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 844/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 845/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3660\n",
            "Epoch 846/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 847/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 848/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 849/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3657\n",
            "Epoch 850/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 851/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3693\n",
            "Epoch 852/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3651\n",
            "Epoch 853/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3663\n",
            "Epoch 854/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3655\n",
            "Epoch 855/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 856/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3663\n",
            "Epoch 857/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 858/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3661\n",
            "Epoch 859/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 860/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 861/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 862/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3651\n",
            "Epoch 863/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 864/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 865/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 866/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 867/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 868/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3676\n",
            "Epoch 869/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3665\n",
            "Epoch 870/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3650\n",
            "Epoch 871/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 872/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3664\n",
            "Epoch 873/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3661\n",
            "Epoch 874/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 875/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 876/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3661\n",
            "Epoch 877/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 878/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3685\n",
            "Epoch 879/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 880/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3663\n",
            "Epoch 881/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 882/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 883/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 884/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 885/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 886/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 887/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 888/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 889/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 890/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 891/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3652\n",
            "Epoch 892/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3662\n",
            "Epoch 893/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 894/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3654\n",
            "Epoch 895/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 896/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 897/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3665\n",
            "Epoch 898/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3655\n",
            "Epoch 899/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 900/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 901/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3661\n",
            "Epoch 902/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3653\n",
            "Epoch 903/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 904/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 905/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3650\n",
            "Epoch 906/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3651\n",
            "Epoch 907/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 908/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3680\n",
            "Epoch 909/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3650\n",
            "Epoch 910/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 911/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3662\n",
            "Epoch 912/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 913/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 914/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 915/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 916/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3653\n",
            "Epoch 917/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3649\n",
            "Epoch 918/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 919/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 920/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 921/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 922/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3655\n",
            "Epoch 923/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 924/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 925/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 926/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3649\n",
            "Epoch 927/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3666\n",
            "Epoch 928/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3669\n",
            "Epoch 929/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 930/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 931/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 932/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3661\n",
            "Epoch 933/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 934/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 935/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3661\n",
            "Epoch 936/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3663\n",
            "Epoch 937/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3663\n",
            "Epoch 938/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 939/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 940/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3664\n",
            "Epoch 941/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3655\n",
            "Epoch 942/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 943/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 944/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 945/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3655\n",
            "Epoch 946/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3662\n",
            "Epoch 947/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3663\n",
            "Epoch 948/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3672\n",
            "Epoch 949/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 950/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3680\n",
            "Epoch 951/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3655\n",
            "Epoch 952/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 953/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 954/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 955/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 956/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 957/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3659\n",
            "Epoch 958/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3665\n",
            "Epoch 959/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 960/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 961/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 962/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 963/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 964/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 965/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3671\n",
            "Epoch 966/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 967/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 968/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3677\n",
            "Epoch 969/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 970/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3659\n",
            "Epoch 971/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3652\n",
            "Epoch 972/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 973/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3681\n",
            "Epoch 974/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3653\n",
            "Epoch 975/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 976/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 977/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3677\n",
            "Epoch 978/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3649\n",
            "Epoch 979/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3675\n",
            "Epoch 980/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3660\n",
            "Epoch 981/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 982/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 983/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3666\n",
            "Epoch 984/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 985/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 986/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3660\n",
            "Epoch 987/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3669\n",
            "Epoch 988/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 989/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 990/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 991/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3660\n",
            "Epoch 992/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3675\n",
            "Epoch 993/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3667\n",
            "Epoch 994/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3650\n",
            "Epoch 995/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 996/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3656\n",
            "Epoch 997/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3653\n",
            "Epoch 998/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3658\n",
            "Epoch 999/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1000/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3663\n",
            "Epoch 1001/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3664\n",
            "Epoch 1002/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3659\n",
            "Epoch 1003/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3669\n",
            "Epoch 1004/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3653\n",
            "Epoch 1005/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3676\n",
            "Epoch 1006/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 1007/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3681\n",
            "Epoch 1008/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 1009/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3652\n",
            "Epoch 1010/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3676\n",
            "Epoch 1011/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3668\n",
            "Epoch 1012/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3667\n",
            "Epoch 1013/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 1014/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3671\n",
            "Epoch 1015/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3020 - val_loss: 0.3654\n",
            "Epoch 1016/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 1017/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 1018/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1019/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3657\n",
            "Epoch 1020/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1021/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1022/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1023/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1024/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3653\n",
            "Epoch 1025/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3678\n",
            "Epoch 1026/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3653\n",
            "Epoch 1027/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3666\n",
            "Epoch 1028/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3656\n",
            "Epoch 1029/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3656\n",
            "Epoch 1030/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 1031/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3664\n",
            "Epoch 1032/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3660\n",
            "Epoch 1033/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1034/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3670\n",
            "Epoch 1035/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3668\n",
            "Epoch 1036/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 1037/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3677\n",
            "Epoch 1038/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 1039/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3685\n",
            "Epoch 1040/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 1041/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3680\n",
            "Epoch 1042/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 1043/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3656\n",
            "Epoch 1044/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 1045/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 1046/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3660\n",
            "Epoch 1047/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3667\n",
            "Epoch 1048/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3666\n",
            "Epoch 1049/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3666\n",
            "Epoch 1050/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 1051/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1052/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1053/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 1054/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 1055/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 1056/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 1057/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3672\n",
            "Epoch 1058/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 1059/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3660\n",
            "Epoch 1060/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1061/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3679\n",
            "Epoch 1062/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3659\n",
            "Epoch 1063/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1064/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3655\n",
            "Epoch 1065/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 1066/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1067/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3663\n",
            "Epoch 1068/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1069/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3661\n",
            "Epoch 1070/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1071/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3664\n",
            "Epoch 1072/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3671\n",
            "Epoch 1073/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 1074/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 1075/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 1076/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1077/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3666\n",
            "Epoch 1078/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3665\n",
            "Epoch 1079/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 1080/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3672\n",
            "Epoch 1081/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3681\n",
            "Epoch 1082/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3668\n",
            "Epoch 1083/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3683\n",
            "Epoch 1084/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 0.3670\n",
            "Epoch 1085/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3665\n",
            "Epoch 1086/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3653\n",
            "Epoch 1087/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1088/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3662\n",
            "Epoch 1089/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1090/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3660\n",
            "Epoch 1091/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3663\n",
            "Epoch 1092/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1093/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 1094/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3662\n",
            "Epoch 1095/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3650\n",
            "Epoch 1096/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3681\n",
            "Epoch 1097/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3651\n",
            "Epoch 1098/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3682\n",
            "Epoch 1099/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3669\n",
            "Epoch 1100/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1101/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 1102/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 1103/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3664\n",
            "Epoch 1104/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 1105/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1106/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1107/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3676\n",
            "Epoch 1108/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3667\n",
            "Epoch 1109/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3661\n",
            "Epoch 1110/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3656\n",
            "Epoch 1111/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3656\n",
            "Epoch 1112/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3659\n",
            "Epoch 1113/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 1114/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 1115/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 1116/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3649\n",
            "Epoch 1117/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3669\n",
            "Epoch 1118/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1119/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3663\n",
            "Epoch 1120/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1121/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3655\n",
            "Epoch 1122/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3659\n",
            "Epoch 1123/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 1124/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3657\n",
            "Epoch 1125/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 1126/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1127/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3649\n",
            "Epoch 1128/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3651\n",
            "Epoch 1129/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1130/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 1131/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 1132/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3670\n",
            "Epoch 1133/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3655\n",
            "Epoch 1134/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3664\n",
            "Epoch 1135/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1136/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1137/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3663\n",
            "Epoch 1138/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 1139/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1140/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.3661\n",
            "Epoch 1141/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 1142/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1143/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3655\n",
            "Epoch 1144/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 1145/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1146/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3666\n",
            "Epoch 1147/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1148/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3672\n",
            "Epoch 1149/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 1150/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1151/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 1152/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 1153/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1154/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1155/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1156/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1157/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3677\n",
            "Epoch 1158/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 1159/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 1160/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1161/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3659\n",
            "Epoch 1162/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1163/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 1164/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 1165/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3670\n",
            "Epoch 1166/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 1167/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1168/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3676\n",
            "Epoch 1169/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3659\n",
            "Epoch 1170/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3651\n",
            "Epoch 1171/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3026 - val_loss: 0.3679\n",
            "Epoch 1172/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1173/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3649\n",
            "Epoch 1174/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1175/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3669\n",
            "Epoch 1176/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1177/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1178/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1179/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1180/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3671\n",
            "Epoch 1181/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.3675\n",
            "Epoch 1182/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3684\n",
            "Epoch 1183/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 1184/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 1185/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 1186/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3664\n",
            "Epoch 1187/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3663\n",
            "Epoch 1188/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3658\n",
            "Epoch 1189/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1190/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3660\n",
            "Epoch 1191/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1192/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3668\n",
            "Epoch 1193/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 1194/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3664\n",
            "Epoch 1195/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3658\n",
            "Epoch 1196/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1197/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 1198/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3668\n",
            "Epoch 1199/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3652\n",
            "Epoch 1200/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1201/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3674\n",
            "Epoch 1202/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 1203/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3664\n",
            "Epoch 1204/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1205/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3681\n",
            "Epoch 1206/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3653\n",
            "Epoch 1207/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1208/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3660\n",
            "Epoch 1209/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1210/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1211/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 1212/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 1213/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 1214/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3668\n",
            "Epoch 1215/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 1216/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3663\n",
            "Epoch 1217/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3664\n",
            "Epoch 1218/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1219/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 1220/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1221/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3674\n",
            "Epoch 1222/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3661\n",
            "Epoch 1223/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 1224/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 1225/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1226/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3666\n",
            "Epoch 1227/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 1228/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3654\n",
            "Epoch 1229/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3674\n",
            "Epoch 1230/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 1231/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 1232/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3664\n",
            "Epoch 1233/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3663\n",
            "Epoch 1234/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3679\n",
            "Epoch 1235/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3659\n",
            "Epoch 1236/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1237/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1238/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 1239/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1240/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1241/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3664\n",
            "Epoch 1242/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1243/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1244/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3649\n",
            "Epoch 1245/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3662\n",
            "Epoch 1246/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 1247/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3649\n",
            "Epoch 1248/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3653\n",
            "Epoch 1249/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3651\n",
            "Epoch 1250/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3659\n",
            "Epoch 1251/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1252/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1253/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1254/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 1255/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1256/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3669\n",
            "Epoch 1257/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3649\n",
            "Epoch 1258/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3671\n",
            "Epoch 1259/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 1260/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3655\n",
            "Epoch 1261/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 1262/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3683\n",
            "Epoch 1263/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 1264/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3673\n",
            "Epoch 1265/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 1266/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1267/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 1268/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3671\n",
            "Epoch 1269/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1270/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3672\n",
            "Epoch 1271/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 1272/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3684\n",
            "Epoch 1273/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1274/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3655\n",
            "Epoch 1275/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3674\n",
            "Epoch 1276/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3663\n",
            "Epoch 1277/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3673\n",
            "Epoch 1278/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1279/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1280/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3672\n",
            "Epoch 1281/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1282/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3664\n",
            "Epoch 1283/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 1284/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 1285/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3668\n",
            "Epoch 1286/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 0.3663\n",
            "Epoch 1287/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3653\n",
            "Epoch 1288/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3670\n",
            "Epoch 1289/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3665\n",
            "Epoch 1290/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3666\n",
            "Epoch 1291/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3658\n",
            "Epoch 1292/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1293/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3668\n",
            "Epoch 1294/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3649\n",
            "Epoch 1295/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 1296/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3659\n",
            "Epoch 1297/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3659\n",
            "Epoch 1298/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 1299/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3661\n",
            "Epoch 1300/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1301/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3684\n",
            "Epoch 1302/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3649\n",
            "Epoch 1303/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1304/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1305/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3662\n",
            "Epoch 1306/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3664\n",
            "Epoch 1307/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3662\n",
            "Epoch 1308/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1309/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 1310/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 1311/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1312/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1313/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1314/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1315/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1316/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 1317/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3650\n",
            "Epoch 1318/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 1319/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3661\n",
            "Epoch 1320/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 1321/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1322/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1323/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1324/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 1325/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1326/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1327/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3660\n",
            "Epoch 1328/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1329/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3654\n",
            "Epoch 1330/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3660\n",
            "Epoch 1331/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3653\n",
            "Epoch 1332/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 1333/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3659\n",
            "Epoch 1334/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1335/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 1336/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3654\n",
            "Epoch 1337/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 1338/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1339/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.3649\n",
            "Epoch 1340/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 1341/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 1342/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3661\n",
            "Epoch 1343/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1344/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 1345/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1346/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3656\n",
            "Epoch 1347/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3658\n",
            "Epoch 1348/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 1349/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3662\n",
            "Epoch 1350/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 1351/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 1352/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 1353/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3667\n",
            "Epoch 1354/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3677\n",
            "Epoch 1355/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3681\n",
            "Epoch 1356/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3666\n",
            "Epoch 1357/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3671\n",
            "Epoch 1358/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1359/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3649\n",
            "Epoch 1360/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1361/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1362/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 1363/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 1364/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3675\n",
            "Epoch 1365/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3657\n",
            "Epoch 1366/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1367/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3652\n",
            "Epoch 1368/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1369/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3657\n",
            "Epoch 1370/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3653\n",
            "Epoch 1371/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1372/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1373/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3666\n",
            "Epoch 1374/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3664\n",
            "Epoch 1375/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3674\n",
            "Epoch 1376/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1377/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 1378/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3671\n",
            "Epoch 1379/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 1380/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1381/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1382/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 1383/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1384/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1385/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 1386/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1387/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3675\n",
            "Epoch 1388/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3656\n",
            "Epoch 1389/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1390/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3663\n",
            "Epoch 1391/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 1392/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3669\n",
            "Epoch 1393/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3649\n",
            "Epoch 1394/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3661\n",
            "Epoch 1395/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 1396/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 1397/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1398/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3652\n",
            "Epoch 1399/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 1400/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1401/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 1402/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 1403/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3651\n",
            "Epoch 1404/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1405/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3657\n",
            "Epoch 1406/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3677\n",
            "Epoch 1407/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 1408/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3652\n",
            "Epoch 1409/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 1410/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3658\n",
            "Epoch 1411/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3662\n",
            "Epoch 1412/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1413/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1414/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3667\n",
            "Epoch 1415/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3663\n",
            "Epoch 1416/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3661\n",
            "Epoch 1417/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1418/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3650\n",
            "Epoch 1419/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1420/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 1421/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1422/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1423/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3656\n",
            "Epoch 1424/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3668\n",
            "Epoch 1425/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1426/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1427/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1428/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 1429/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1430/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3667\n",
            "Epoch 1431/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 1432/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 1433/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1434/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3667\n",
            "Epoch 1435/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3666\n",
            "Epoch 1436/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3661\n",
            "Epoch 1437/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 1438/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1439/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 1440/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 1441/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1442/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1443/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 1444/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3672\n",
            "Epoch 1445/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3659\n",
            "Epoch 1446/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 1447/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 1448/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1449/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 1450/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 1451/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3669\n",
            "Epoch 1452/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3662\n",
            "Epoch 1453/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3650\n",
            "Epoch 1454/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3659\n",
            "Epoch 1455/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3665\n",
            "Epoch 1456/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1457/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1458/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3669\n",
            "Epoch 1459/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3662\n",
            "Epoch 1460/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3663\n",
            "Epoch 1461/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3663\n",
            "Epoch 1462/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3664\n",
            "Epoch 1463/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3689\n",
            "Epoch 1464/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3674\n",
            "Epoch 1465/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 1466/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1467/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1468/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 1469/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 1470/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3654\n",
            "Epoch 1471/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3662\n",
            "Epoch 1472/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1473/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3661\n",
            "Epoch 1474/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 1475/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1476/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3678\n",
            "Epoch 1477/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3660\n",
            "Epoch 1478/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 1479/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 1480/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1481/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 1482/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3651\n",
            "Epoch 1483/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3650\n",
            "Epoch 1484/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3674\n",
            "Epoch 1485/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3021 - val_loss: 0.3666\n",
            "Epoch 1486/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 1487/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3659\n",
            "Epoch 1488/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 1489/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1490/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3669\n",
            "Epoch 1491/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 1492/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1493/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1494/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3667\n",
            "Epoch 1495/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3659\n",
            "Epoch 1496/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3672\n",
            "Epoch 1497/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3674\n",
            "Epoch 1498/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3660\n",
            "Epoch 1499/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3652\n",
            "Epoch 1500/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3650\n",
            "Epoch 1501/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3660\n",
            "Epoch 1502/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3664\n",
            "Epoch 1503/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 1504/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3664\n",
            "Epoch 1505/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3666\n",
            "Epoch 1506/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3007 - val_loss: 0.3658\n",
            "Epoch 1507/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 1508/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3664\n",
            "Epoch 1509/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1510/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1511/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3676\n",
            "Epoch 1512/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1513/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3654\n",
            "Epoch 1514/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3649\n",
            "Epoch 1515/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 1516/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3673\n",
            "Epoch 1517/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3661\n",
            "Epoch 1518/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3665\n",
            "Epoch 1519/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3651\n",
            "Epoch 1520/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1521/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.3651\n",
            "Epoch 1522/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3659\n",
            "Epoch 1523/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1524/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 1525/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1526/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3671\n",
            "Epoch 1527/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 1528/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 1529/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1530/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 1531/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1532/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1533/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3659\n",
            "Epoch 1534/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3669\n",
            "Epoch 1535/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1536/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3674\n",
            "Epoch 1537/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3699\n",
            "Epoch 1538/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3651\n",
            "Epoch 1539/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3659\n",
            "Epoch 1540/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3667\n",
            "Epoch 1541/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 1542/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1543/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3656\n",
            "Epoch 1544/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 1545/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3671\n",
            "Epoch 1546/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3660\n",
            "Epoch 1547/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1548/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3682\n",
            "Epoch 1549/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3671\n",
            "Epoch 1550/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3672\n",
            "Epoch 1551/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3651\n",
            "Epoch 1552/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 1553/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3663\n",
            "Epoch 1554/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1555/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3656\n",
            "Epoch 1556/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1557/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3651\n",
            "Epoch 1558/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3664\n",
            "Epoch 1559/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3669\n",
            "Epoch 1560/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3657\n",
            "Epoch 1561/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3663\n",
            "Epoch 1562/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 1563/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3649\n",
            "Epoch 1564/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3679\n",
            "Epoch 1565/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1566/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3651\n",
            "Epoch 1567/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3658\n",
            "Epoch 1568/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3667\n",
            "Epoch 1569/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3675\n",
            "Epoch 1570/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3663\n",
            "Epoch 1571/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 1572/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3649\n",
            "Epoch 1573/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3667\n",
            "Epoch 1574/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3671\n",
            "Epoch 1575/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3015 - val_loss: 0.3678\n",
            "Epoch 1576/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3658\n",
            "Epoch 1577/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3653\n",
            "Epoch 1578/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3668\n",
            "Epoch 1579/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3655\n",
            "Epoch 1580/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1581/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3650\n",
            "Epoch 1582/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1583/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1584/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1585/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1586/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3650\n",
            "Epoch 1587/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3666\n",
            "Epoch 1588/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3664\n",
            "Epoch 1589/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 1590/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1591/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3660\n",
            "Epoch 1592/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3667\n",
            "Epoch 1593/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1594/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1595/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3672\n",
            "Epoch 1596/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3682\n",
            "Epoch 1597/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 1598/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1599/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3667\n",
            "Epoch 1600/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1601/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 1602/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3661\n",
            "Epoch 1603/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 1604/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3661\n",
            "Epoch 1605/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3665\n",
            "Epoch 1606/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3655\n",
            "Epoch 1607/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3665\n",
            "Epoch 1608/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3658\n",
            "Epoch 1609/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3657\n",
            "Epoch 1610/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3005 - val_loss: 0.3676\n",
            "Epoch 1611/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3669\n",
            "Epoch 1612/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3654\n",
            "Epoch 1613/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3672\n",
            "Epoch 1614/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3649\n",
            "Epoch 1615/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 1616/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3662\n",
            "Epoch 1617/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 1618/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3651\n",
            "Epoch 1619/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1620/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3661\n",
            "Epoch 1621/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3656\n",
            "Epoch 1622/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3667\n",
            "Epoch 1623/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 1624/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1625/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3652\n",
            "Epoch 1626/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3651\n",
            "Epoch 1627/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 1628/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1629/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1630/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 1631/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 1632/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 1633/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1634/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3678\n",
            "Epoch 1635/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3659\n",
            "Epoch 1636/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3662\n",
            "Epoch 1637/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3684\n",
            "Epoch 1638/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.3662\n",
            "Epoch 1639/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3015 - val_loss: 0.3651\n",
            "Epoch 1640/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1641/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3652\n",
            "Epoch 1642/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1643/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 1644/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1645/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 1646/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3655\n",
            "Epoch 1647/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3654\n",
            "Epoch 1648/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1649/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 1650/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3655\n",
            "Epoch 1651/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3664\n",
            "Epoch 1652/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3669\n",
            "Epoch 1653/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3686\n",
            "Epoch 1654/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3655\n",
            "Epoch 1655/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 1656/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 1657/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3661\n",
            "Epoch 1658/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3015 - val_loss: 0.3663\n",
            "Epoch 1659/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1660/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3666\n",
            "Epoch 1661/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3649\n",
            "Epoch 1662/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3016 - val_loss: 0.3651\n",
            "Epoch 1663/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.3692\n",
            "Epoch 1664/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3653\n",
            "Epoch 1665/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 1666/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1667/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3665\n",
            "Epoch 1668/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3659\n",
            "Epoch 1669/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3672\n",
            "Epoch 1670/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 1671/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3670\n",
            "Epoch 1672/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3676\n",
            "Epoch 1673/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3655\n",
            "Epoch 1674/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1675/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3653\n",
            "Epoch 1676/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3667\n",
            "Epoch 1677/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3663\n",
            "Epoch 1678/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3659\n",
            "Epoch 1679/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3665\n",
            "Epoch 1680/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 1681/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1682/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 1683/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3666\n",
            "Epoch 1684/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3655\n",
            "Epoch 1685/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 1686/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1687/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3650\n",
            "Epoch 1688/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3652\n",
            "Epoch 1689/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3666\n",
            "Epoch 1690/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1691/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3649\n",
            "Epoch 1692/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3652\n",
            "Epoch 1693/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1694/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3687\n",
            "Epoch 1695/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3656\n",
            "Epoch 1696/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1697/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3655\n",
            "Epoch 1698/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3656\n",
            "Epoch 1699/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 1700/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 1701/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1702/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1703/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3669\n",
            "Epoch 1704/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3659\n",
            "Epoch 1705/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 1706/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1707/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3674\n",
            "Epoch 1708/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3650\n",
            "Epoch 1709/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 1710/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1711/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3650\n",
            "Epoch 1712/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3667\n",
            "Epoch 1713/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3658\n",
            "Epoch 1714/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 1715/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 1716/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3664\n",
            "Epoch 1717/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3661\n",
            "Epoch 1718/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 1719/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3651\n",
            "Epoch 1720/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3664\n",
            "Epoch 1721/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3659\n",
            "Epoch 1722/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3659\n",
            "Epoch 1723/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3677\n",
            "Epoch 1724/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3654\n",
            "Epoch 1725/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3667\n",
            "Epoch 1726/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3677\n",
            "Epoch 1727/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3655\n",
            "Epoch 1728/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3662\n",
            "Epoch 1729/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1730/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3662\n",
            "Epoch 1731/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3649\n",
            "Epoch 1732/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 1733/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 1734/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 1735/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1736/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1737/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3660\n",
            "Epoch 1738/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1739/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3657\n",
            "Epoch 1740/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3012 - val_loss: 0.3668\n",
            "Epoch 1741/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3659\n",
            "Epoch 1742/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1743/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 1744/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1745/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3660\n",
            "Epoch 1746/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1747/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3662\n",
            "Epoch 1748/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3669\n",
            "Epoch 1749/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3020 - val_loss: 0.3668\n",
            "Epoch 1750/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1751/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3659\n",
            "Epoch 1752/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3660\n",
            "Epoch 1753/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3652\n",
            "Epoch 1754/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3664\n",
            "Epoch 1755/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1756/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 1757/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 1758/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3661\n",
            "Epoch 1759/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3010 - val_loss: 0.3655\n",
            "Epoch 1760/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1761/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3657\n",
            "Epoch 1762/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1763/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1764/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 1765/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3655\n",
            "Epoch 1766/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3651\n",
            "Epoch 1767/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 1768/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.3661\n",
            "Epoch 1769/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1770/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1771/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 1772/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 1773/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3677\n",
            "Epoch 1774/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3660\n",
            "Epoch 1775/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1776/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3650\n",
            "Epoch 1777/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3669\n",
            "Epoch 1778/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3654\n",
            "Epoch 1779/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1780/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 1781/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1782/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1783/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3654\n",
            "Epoch 1784/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.3652\n",
            "Epoch 1785/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1786/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.3651\n",
            "Epoch 1787/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3653\n",
            "Epoch 1788/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 1789/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3671\n",
            "Epoch 1790/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3675\n",
            "Epoch 1791/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 1792/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3653\n",
            "Epoch 1793/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3654\n",
            "Epoch 1794/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1795/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1796/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1797/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3652\n",
            "Epoch 1798/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3657\n",
            "Epoch 1799/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 1800/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3652\n",
            "Epoch 1801/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3657\n",
            "Epoch 1802/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3656\n",
            "Epoch 1803/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3662\n",
            "Epoch 1804/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3660\n",
            "Epoch 1805/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3660\n",
            "Epoch 1806/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3665\n",
            "Epoch 1807/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3664\n",
            "Epoch 1808/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 1809/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3679\n",
            "Epoch 1810/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3671\n",
            "Epoch 1811/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1812/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3654\n",
            "Epoch 1813/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3660\n",
            "Epoch 1814/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3662\n",
            "Epoch 1815/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3663\n",
            "Epoch 1816/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3659\n",
            "Epoch 1817/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3659\n",
            "Epoch 1818/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3660\n",
            "Epoch 1819/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1820/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3660\n",
            "Epoch 1821/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3661\n",
            "Epoch 1822/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.3661\n",
            "Epoch 1823/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3651\n",
            "Epoch 1824/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3649\n",
            "Epoch 1825/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3665\n",
            "Epoch 1826/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.3664\n",
            "Epoch 1827/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3670\n",
            "Epoch 1828/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 1829/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3665\n",
            "Epoch 1830/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3661\n",
            "Epoch 1831/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3663\n",
            "Epoch 1832/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3015 - val_loss: 0.3649\n",
            "Epoch 1833/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.3661\n",
            "Epoch 1834/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.3674\n",
            "Epoch 1835/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3660\n",
            "Epoch 1836/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1837/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3658\n",
            "Epoch 1838/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1839/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3666\n",
            "Epoch 1840/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1841/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3660\n",
            "Epoch 1842/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3663\n",
            "Epoch 1843/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3656\n",
            "Epoch 1844/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3663\n",
            "Epoch 1845/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1846/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3656\n",
            "Epoch 1847/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3657\n",
            "Epoch 1848/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3652\n",
            "Epoch 1849/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1850/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3649\n",
            "Epoch 1851/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3654\n",
            "Epoch 1852/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3656\n",
            "Epoch 1853/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3653\n",
            "Epoch 1854/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1855/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 1856/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n",
            "Epoch 1857/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3652\n",
            "Epoch 1858/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.3657\n",
            "Epoch 1859/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3649\n",
            "Epoch 1860/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1861/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3654\n",
            "Epoch 1862/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3003 - val_loss: 0.3666\n",
            "Epoch 1863/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3671\n",
            "Epoch 1864/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3653\n",
            "Epoch 1865/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1866/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3657\n",
            "Epoch 1867/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1868/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1869/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3659\n",
            "Epoch 1870/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3649\n",
            "Epoch 1871/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.3664\n",
            "Epoch 1872/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3015 - val_loss: 0.3694\n",
            "Epoch 1873/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3013 - val_loss: 0.3660\n",
            "Epoch 1874/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3651\n",
            "Epoch 1875/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3655\n",
            "Epoch 1876/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3658\n",
            "Epoch 1877/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1878/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.3667\n",
            "Epoch 1879/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3668\n",
            "Epoch 1880/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3018 - val_loss: 0.3681\n",
            "Epoch 1881/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3012 - val_loss: 0.3662\n",
            "Epoch 1882/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1883/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3656\n",
            "Epoch 1884/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3654\n",
            "Epoch 1885/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1886/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 1887/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3657\n",
            "Epoch 1888/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1889/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3664\n",
            "Epoch 1890/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3651\n",
            "Epoch 1891/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3676\n",
            "Epoch 1892/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3676\n",
            "Epoch 1893/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3663\n",
            "Epoch 1894/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3655\n",
            "Epoch 1895/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1896/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3650\n",
            "Epoch 1897/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3665\n",
            "Epoch 1898/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3009 - val_loss: 0.3651\n",
            "Epoch 1899/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3653\n",
            "Epoch 1900/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 1901/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3649\n",
            "Epoch 1902/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3668\n",
            "Epoch 1903/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3002 - val_loss: 0.3655\n",
            "Epoch 1904/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3649\n",
            "Epoch 1905/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3016 - val_loss: 0.3659\n",
            "Epoch 1906/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.3654\n",
            "Epoch 1907/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 1908/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3677\n",
            "Epoch 1909/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3015 - val_loss: 0.3668\n",
            "Epoch 1910/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3657\n",
            "Epoch 1911/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3658\n",
            "Epoch 1912/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3649\n",
            "Epoch 1913/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3668\n",
            "Epoch 1914/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3676\n",
            "Epoch 1915/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3010 - val_loss: 0.3693\n",
            "Epoch 1916/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3025 - val_loss: 0.3660\n",
            "Epoch 1917/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3660\n",
            "Epoch 1918/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3652\n",
            "Epoch 1919/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3655\n",
            "Epoch 1920/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1921/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1922/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3663\n",
            "Epoch 1923/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 1924/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1925/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3655\n",
            "Epoch 1926/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3658\n",
            "Epoch 1927/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3655\n",
            "Epoch 1928/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3652\n",
            "Epoch 1929/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3657\n",
            "Epoch 1930/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3667\n",
            "Epoch 1931/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3013 - val_loss: 0.3657\n",
            "Epoch 1932/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3669\n",
            "Epoch 1933/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3010 - val_loss: 0.3660\n",
            "Epoch 1934/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3649\n",
            "Epoch 1935/2000\n",
            "43/43 [==============================] - 0s 6ms/step - loss: 0.3007 - val_loss: 0.3662\n",
            "Epoch 1936/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3007 - val_loss: 0.3652\n",
            "Epoch 1937/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.2999 - val_loss: 0.3656\n",
            "Epoch 1938/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3658\n",
            "Epoch 1939/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.3649\n",
            "Epoch 1940/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3663\n",
            "Epoch 1941/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.3653\n",
            "Epoch 1942/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3652\n",
            "Epoch 1943/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.3666\n",
            "Epoch 1944/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3654\n",
            "Epoch 1945/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3652\n",
            "Epoch 1946/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.3650\n",
            "Epoch 1947/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.3650\n",
            "Epoch 1948/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3650\n",
            "Epoch 1949/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 1950/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3670\n",
            "Epoch 1951/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3662\n",
            "Epoch 1952/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1953/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3006 - val_loss: 0.3651\n",
            "Epoch 1954/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3670\n",
            "Epoch 1955/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3002 - val_loss: 0.3649\n",
            "Epoch 1956/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3003 - val_loss: 0.3661\n",
            "Epoch 1957/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.3677\n",
            "Epoch 1958/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3653\n",
            "Epoch 1959/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3660\n",
            "Epoch 1960/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 1961/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3653\n",
            "Epoch 1962/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3654\n",
            "Epoch 1963/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3005 - val_loss: 0.3658\n",
            "Epoch 1964/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1965/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3668\n",
            "Epoch 1966/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3013 - val_loss: 0.3651\n",
            "Epoch 1967/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3656\n",
            "Epoch 1968/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3002 - val_loss: 0.3651\n",
            "Epoch 1969/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.3654\n",
            "Epoch 1970/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3000 - val_loss: 0.3655\n",
            "Epoch 1971/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3650\n",
            "Epoch 1972/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.3660\n",
            "Epoch 1973/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3650\n",
            "Epoch 1974/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1975/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.2998 - val_loss: 0.3659\n",
            "Epoch 1976/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3001 - val_loss: 0.3654\n",
            "Epoch 1977/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.3680\n",
            "Epoch 1978/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3650\n",
            "Epoch 1979/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.3657\n",
            "Epoch 1980/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3007 - val_loss: 0.3665\n",
            "Epoch 1981/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3653\n",
            "Epoch 1982/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.3660\n",
            "Epoch 1983/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3006 - val_loss: 0.3656\n",
            "Epoch 1984/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3667\n",
            "Epoch 1985/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.3652\n",
            "Epoch 1986/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3651\n",
            "Epoch 1987/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.3664\n",
            "Epoch 1988/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3007 - val_loss: 0.3673\n",
            "Epoch 1989/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.3699\n",
            "Epoch 1990/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3650\n",
            "Epoch 1991/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3000 - val_loss: 0.3651\n",
            "Epoch 1992/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.3661\n",
            "Epoch 1993/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.3670\n",
            "Epoch 1994/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3655\n",
            "Epoch 1995/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3653\n",
            "Epoch 1996/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.3662\n",
            "Epoch 1997/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3004 - val_loss: 0.3661\n",
            "Epoch 1998/2000\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.3002 - val_loss: 0.3652\n",
            "Epoch 1999/2000\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3003 - val_loss: 0.3664\n",
            "Epoch 2000/2000\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5oEOEyaF9X8",
        "outputId": "baae2ee7-753e-40b5-a55e-077bae0694a9"
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred[8]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.998433], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TymBwCcyGDAP",
        "outputId": "ab47226b-9a51-4d12-a850-d7b23b4aabda"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39589419960975647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "gjMtZ9mnGGta",
        "outputId": "cca264ac-7e46-4cda-cf9f-6aeec69a037b"
      },
      "source": [
        "#Learning Curve\n",
        "from matplotlib import pyplot\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.plot(predict.history['loss'], label='train')\n",
        "pyplot.plot(predict.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdZX3v8c9v7b3nkmRCJhdISAITFBAQCRoQCrb01Cqggj0q4LVSldYXVvDSFsup5Xj0lNZTTw/1wgsLKi1QEUrFvkDFlosXUBKMEO7hmoSQTO4zmeve63f+eJ69Z8+wZ5gks/eesL7v12tes/e6/taz116/9TzP2muZuyMiItmVNDsAERFpLiUCEZGMUyIQEck4JQIRkYxTIhARyTglAhGRjFMiEBnDzN5kZo83Ow6RRlEikGnFzJ41szc3MwZ3/6m7H1mv5ZvZW83sHjPrMbNuM7vbzM6q1/pEXo4SgWSOmeWauO53A98DrgWWAAcBnwfesRfLMjPTd1j2mXYi2S+YWWJml5jZU2a21cxuNLO5VeO/Z2YvmtnOeLZ9TNW4b5vZN8zsNjPbDfxurHl81swejPN818za4vSnmdn6qvnHnTaO/3Mz22hmL5jZR83MzezVNbbBgK8A/8vd/8ndd7p76u53u/vH4jSXmdm/VM3TFZeXj+/vMrMvmdnPgT7gz8xs5Zj1fMrMbo2vW83s/5jZ82a2ycyuNLP2OG6+mf2Hme0ws21m9lMllmzShy77iz8F3gn8DnAwsB34WtX424HDgQOBB4Drxsz/PuBLQAfwszjsHOB0YBnwOuDDE6y/5rRmdjrwaeDNwKuB0yZYxpHAUuCmCaaZjA8CFxC25UrgSDM7vGr8+4Dr4+vLgSOA5TG+xYQaCMBngPXAAkLN5C8B3XMmg5QIZH/xJ8Cl7r7e3QeBy4B3l8+U3f0ad++pGnecmR1QNf/33f3n8Qx8IA67wt1fcPdtwA8IB8vxjDftOcC33P1hd++L6x7PvPh/42Q3ehzfjusruvtO4PvAewFiQngNcGusgVwAfMrdt7l7D/C/gfPicoaBRcCh7j4c+0aUCDJIiUD2F4cCt8RmjB3Ao0AJOMjMcmZ2eWw22gU8G+eZXzX/uhrLfLHqdR8wa4L1jzftwWOWXWs9ZVvj/0UTTDMZY9dxPTEREGoD/x6T0gJgBrCqqtx+GIcDfBlYC/zYzJ42s0v2MS7ZTykRyP5iHXCGu8+p+mtz9w2Eg9/ZhOaZA4CuOI9VzV+vM92NhE7fsqUTTPs4YTveNcE0uwkH77KFNaYZuy13AAvMbDkhIZSbhbYA/cAxVWV2gLvPAog1qM+4+2HAWcCnzez3JohNXqGUCGQ6KphZW9VfntAW/iUzOxTAzBaY2dlx+g5gkHDGPYPQ/NEoNwLnm9lRZjYD+KvxJozNLp8G/srMzjez2bET/FQzuypOthr4bTM7JDZtfe7lAnD3YcKVSF8G5hISA+6eAt8E/q+ZHQhgZovN7K3x9dvN7NWxCWknoYaV7k0hyP5NiUCmo9sIZ7Llv8uA/wfcSmjG6AHuA94Yp78WeA7YADwSxzWEu98OXAHcSWhmKa97cJzpbwLOBf4IeAHYBHyR0M6Pu98BfBd4EFgF/MckQ7meUCP6nrsXq4b/RTmu2Gz2E0KnNYTO9Z8AvcC9wNfd/c5Jrk9eQUx9QyJTx8yOAtYArWMOyCLTlmoEIvvIzP4gXq/fCfwt8AMlAdmfKBGI7Ls/BjYDTxHa2T/e3HBE9oyahkREMk41AhGRjMs3O4A9NX/+fO/q6mp2GCIi+5VVq1ZtcfcFtcbtd4mgq6uLlStXvvyEIiJSYWbPjTdOTUMiIhmnRCAiknFKBCIiGbff9RGIiOyN4eFh1q9fz8DAwMtPvB9ra2tjyZIlFAqFSc+jRCAimbB+/Xo6Ojro6uoi3Gfvlcfd2bp1K+vXr2fZsmWTnk9NQyKSCQMDA8ybN+8VmwQAzIx58+btca1HiUBEMuOVnATK9mYbM5MIHn+xh7//8eNs6a15d2ARkczKTCJYu7mXf/yvtWzbPdTsUEQkg3bs2MHXv/71PZ7vzDPPZMeOHXWIaERmEkESa0ulVDfZE5HGGy8RFIsT37H8tttuY86cOfUKC8jQVUNJzASp7rYqIk1wySWX8NRTT7F8+XIKhQJtbW10dnby2GOP8cQTT/DOd76TdevWMTAwwEUXXcQFF1wAjNxWp7e3lzPOOINTTz2VX/ziFyxevJjvf//7tLe373Ns2UkEsQMl1RNZRTLvf/7gYR55YdeULvPog2fz1+84Ztzxl19+OWvWrGH16tXcddddvO1tb2PNmjWVyzyvueYa5s6dS39/PyeccALvete7mDdv3qhlPPnkk9xwww1885vf5JxzzuHmm2/mAx/4wD7HnplEkIuNYCXVCERkGjjxxBNHXet/xRVXcMsttwCwbt06nnzyyZckgmXLlrF8+XIA3vCGN/Dss89OSSyZSQSVGoESgUjmTXTm3igzZ86svL7rrrv4yU9+wr333suMGTM47bTTav4WoLW1tfI6l8vR398/JbFkqLO43DSkRCAijdfR0UFPT0/NcTt37qSzs5MZM2bw2GOPcd999zU0tszUCHKVzuImByIimTRv3jxOOeUUXvva19Le3s5BBx1UGXf66adz5ZVXctRRR3HkkUdy0kknNTS2zCQC0+WjItJk119/fc3hra2t3H777TXHlfsB5s+fz5o1ayrDP/vZz05ZXHVrGjKzpWZ2p5k9YmYPm9lFNaY5zcx2mtnq+Pf5esWTi5nA1UcgIjJKPWsEReAz7v6AmXUAq8zsDnd/ZMx0P3X3t9cxDmDkdwS6akhEZLS61QjcfaO7PxBf9wCPAovrtb6XU+4sVtOQiMhoDblqyMy6gOOBX9YYfbKZ/cbMbjezmtd0mdkFZrbSzFZ2d3fvVQzlW0yoQiAiMlrdE4GZzQJuBi5297E/5XsAONTdjwP+Efj3Wstw96vcfYW7r1iwYMFexVG+akg1AhGR0eqaCMysQEgC17n7v40d7+673L03vr4NKJjZ/HrEoh+UiYjUVs+rhgy4GnjU3b8yzjQL43SY2Ykxnq31iEeJQET2J7NmzWrYuup51dApwAeBh8xsdRz2l8AhAO5+JfBu4ONmVgT6gfO8Ttd36gdlIiK11S0RuPvPgAmfmebuXwW+Wq8Yqul5BCLSTJdccglLly7lwgsvBOCyyy4jn89z5513sn37doaHh/niF7/I2Wef3fDYMvPLYj2PQEQqbr8EXnxoape58Fg44/JxR5977rlcfPHFlURw44038qMf/YhPfvKTzJ49my1btnDSSSdx1llnNfzZytlJBOojEJEmOv7449m8eTMvvPAC3d3ddHZ2snDhQj71qU9xzz33kCQJGzZsYNOmTSxcuLChsWUmEeQqPyhrciAi0nwTnLnX03ve8x5uuukmXnzxRc4991yuu+46uru7WbVqFYVCga6urpq3n663zCSCck1LNQIRaZZzzz2Xj33sY2zZsoW7776bG2+8kQMPPJBCocCdd97Jc88915S4MpMIKlcNqbNYRJrkmGOOoaenh8WLF7No0SLe//738453vINjjz2WFStW8JrXvKYpcWUvESgPiEgTPfTQSCf1/Pnzuffee2tO19vb26iQsvOEssrzCNQ0JCIySmYSgZ5HICJSW2YSgW5DLSJZOBHcm23MTiJQH4FIprW1tbF169ZXdDJwd7Zu3UpbW9sezZeZzuLyLSZ01ZBINi1ZsoT169ezt8802V+0tbWxZMmSPZonM4kgp0dVimRaoVBg2bJlzQ5jWspO05BuMSEiUlP2EoGahkRERslMItAPykREastMItDzCEREastMIrC+bZyQPEau2N/sUEREppXMJAKeuZvvtXyBWQMbmh2JiMi0kp1EoFtMiIjUlKFEEDbVUz2ZRkSkWnYSAeXLR5UIRESqZScRqGlIRKSmDCWC2DTkqhGIiFTLTiKgXCNQIhARqZadRFBuGtIPykRERslQIig3DSkRiIhUy04iKDcNpaUmxyEiMr1kJxHoNtQiIjVlLhGos1hEZLTsJAIqz6psbhgiItNMdhKBflAmIlJThhJB2FT1EYiIjJadRBCbhkx9BCIio9QtEZjZUjO708weMbOHzeyiGtOYmV1hZmvN7EEze3294hm5akiJQESkWr6Oyy4Cn3H3B8ysA1hlZne4+yNV05wBHB7/3gh8I/6vA/URiIjUUrcagbtvdPcH4use4FFg8ZjJzgau9eA+YI6ZLapLQLGPQFcNiYiM1pA+AjPrAo4Hfjlm1GJgXdX79bw0WWBmF5jZSjNb2d3dvbdBAOosFhEZq+6JwMxmATcDF7v7rr1Zhrtf5e4r3H3FggUL9jaS8rL2cn4RkVemuiYCMysQksB17v5vNSbZACyter8kDqtDMHoegYhILfW8asiAq4FH3f0r40x2K/ChePXQScBOd99Yp4DCfyUCEZFR6nnV0CnAB4GHzGx1HPaXwCEA7n4lcBtwJrAW6APOr184eh6BiEgtdUsE7v4zKjf4GXcaBy6sVwyjlK8aQolARKRadn5ZXG4ZUtOQiMgo2UkEumpIRKSm7CQC/aBMRKSmDCWCWCNAiUBEpFp2EoGuGhIRqSk7iaDcNKQ+AhGRUTKUCMpXsqppSESkWnYSQWwaStU0JCIySnYSgZqGRERqylAiUNOQiEgt2UkE+kGZiEhN2UkEahoSEakpQ4kgNg3pl8UiIqNkJxFE+mWxiMho2UkElQfTqGlIRKRahhJB+VGVTY5DRGSayU4iQI+qFBGpJTuJQHcfFRGpKUOJoPw8ArUNiYhUy04iQL8sFhGpJTuJQFcNiYjUlKFEUL5qSIlARKRadhJBbBoyXTUkIjJKdhJB5aoh1QpERKplKBGETTVc3QQiIlWykwhi01CCU1ImEBGpyE4iiE1DhpMqEYiIVGQzEai/WESkIjuJQE1DIiI1ZScRVJ5ZrKYhEZFqGUoE5auGINX9hkREKrKTCCpNQ6nuOyciUiU7iaDSWQwlZQIRkYpJJQIzu8jMZltwtZk9YGZveZl5rjGzzWa2Zpzxp5nZTjNbHf8+vzcbMHkjVw3pl8UiIiMmWyP4I3ffBbwF6AQ+CFz+MvN8Gzj9Zab5qbsvj39fmGQseyf2EeiqIRGR0SabCMqX3JwJ/LO7P1w1rCZ3vwfYtg+xTa3yg2lw9RGIiFSZbCJYZWY/JiSCH5lZB1PzhJeTzew3Zna7mR0z3kRmdoGZrTSzld3d3Xu3pqoaga4aEhEZkZ/kdB8BlgNPu3ufmc0Fzt/HdT8AHOruvWZ2JvDvwOG1JnT3q4CrAFasWLF3R/HqpiElAhGRisnWCE4GHnf3HWb2AeB/ADv3ZcXuvsvde+Pr24CCmc3fl2VOKF41lFiqH5SJiFSZbCL4BtBnZscBnwGeAq7dlxWb2UKzcHQ2sxNjLFv3ZZkvs0Ic003nRETGmGzTUNHd3czOBr7q7leb2UcmmsHMbgBOA+ab2Xrgr4ECgLtfCbwb+LiZFYF+4Dyv83WdbknoI1AeEBGpmGwi6DGzzxEuG32TmSXEg/p43P29LzP+q8BXJ7n+KZKQkKqPQESkymSbhs4FBgm/J3gRWAJ8uW5R1YmbxRqBEoGISNmkEkE8+F8HHGBmbwcG3H2f+giawhI9j0BEZIzJ3mLiHOBXwHuAc4Bfmtm76xlYPYz0EahGICJSNtk+gkuBE9x9M4CZLQB+AtxUr8Dqw0IfgRKBiEjFZPsIknISiLbuwbzTR7lGoM5iEZGKydYIfmhmPwJuiO/PBW6rT0j14+U+AuUBEZGKSSUCd/8zM3sXcEocdJW731K/sOrEdPmoiMhYk60R4O43AzfXMZb6s4QcqZ5HICJSZcJEYGY9QK2jpgHu7rPrElXdmJ5HICIyxoSJwN07GhVII3iSUx+BiMgY+9+VP/tCVw2JiLxEBhOBOotFRKplKxGQkJh+WSwiUi1bicD0PAIRkbEylghC05BahkRERmQwEeiZxSIi1bKVCBLdfVREZKxsJQJLMPTwehGRaplLBIkeTCMiMkomE4FuMSEiMiJTicD0y2IRkZfIVCIY6SNodiAiItNH5hKBmoZEREbLZCLQ8whEREZkKhGYbjonIvISmUoEJHpmsYjIWNlKBLpqSETkJTKVCCqXj6qPQESkIlOJgCQhsVRXDYmIVMlUIjCLfQRqGhIRqchUIqj0ESgPiIhUZCoRWKLLR0VExspWItAPykREXiJTiUC3mBAReam6JQIzu8bMNpvZmnHGm5ldYWZrzexBM3t9vWIZWWlCYuojEBGpVs8awbeB0ycYfwZwePy7APhGHWMJLCFHSrGkJ9OIiJTVLRG4+z3AtgkmORu41oP7gDlmtqhe8QBgCXlzegdLdV2NiMj+pJl9BIuBdVXv18dhL2FmF5jZSjNb2d3dvfdrtIR8Ar2Dxb1fhojIK8x+0Vns7le5+wp3X7FgwYK9X5Al5HD6lAhERCqamQg2AEur3i+Jw+ondhYPq7dYRKSimYngVuBD8eqhk4Cd7r6xrmuMl4+qs1hEZES+Xgs2sxuA04D5ZrYe+GugAODuVwK3AWcCa4E+4Px6xTISVPhlcbGkGoGISFndEoG7v/dlxjtwYb3WX1OsEQypRiAiUrFfdBZPmXLTUKpEICJSls1EoKYhEZGKjCUCwyxV05CISJWMJYJ40zldPioiUpG5RGCupiERkWqZSwR6MI2IyGiZSwSGU1QiEBGpyFYiSHIklCjp8lERkYqMJYI8OS+qRiAiUiVbiSDXQs6H1UcgIlIlg4mgpF8Wi4hUyVgiCLdWSlI9j0BEpCxjiaAFgCQdJtzzTkREMpkI8qjDWESkLFuJIAlNQy2U1GEsIhJlKxHEGkFBNQIRkYpMJoK8FfnVM1ubHIyIyPSQsURQAKCFIn/3w8ebHIyIyPSQyURQoMSu/uEmByMiMj1kLBGMXDU0WNSPykREIGuJIBlpGlIiEBEJspUIqpqGOmcWmhyMiMj0kG92AA0Vm4Y62yDXOaPJwYiITA+ZrBEcc1A73T2DTQ5GRGR6yGQimNdmbFYiEBEBMpcIQtPQzIKze7CoG8+JiJC1RBCvGpqRL1FMnYFhXTkkIpKtRBCbhtqtBED/cKmZ0YiITAvZSgSFdgBaGAJguKQagYhIthJBy0wAhvp6ALj+l883MxoRkWkhW4kgH2oE/btDIvju/euaGY2IyLSQrUSQJFCYyUwGABgoqo9ARCRbiQCgZQYzLPyGQE8pExGpcyIws9PN7HEzW2tml9QY/2Ez6zaz1fHvo/WMB4CWmbx2QQ6AzhktdV+diMh0V7d7DZlZDvga8PvAeuB+M7vV3R8ZM+l33f0T9YrjJVo6yA/3AvD8tj7S1EkSa9jqRUSmm3rWCE4E1rr70+4+BPwrcHYd1zc5C46ATY9w2IJwBVHPYLHJAYmINFc9E8FioPqynPVx2FjvMrMHzewmM1taa0FmdoGZrTSzld3d3fsW1aLlsPN5Lj55HgDrtvXt2/JERPZzze4s/gHQ5e6vA+4AvlNrIne/yt1XuPuKBQsW7NsaO7sAWPjsLQD88T+v2rfliYjs5+qZCDYA1Wf4S+KwCnff6u7l24D+E/CGOsYTlMKvik984u8BaG/J1X2VIiLTWT0Twf3A4Wa2zMxagPOAW6snMLNFVW/PAh6tYzzBISfHlYdNP+VV8+q+ShGR6axuicDdi8AngB8RDvA3uvvDZvYFMzsrTvZJM3vYzH4DfBL4cL3iqThgMSz/ALTN4Y2HzuaXz2yr+ypFRKazuvYRuPtt7n6Eu7/K3b8Uh33e3W+Nrz/n7se4+3Hu/rvu/lg946k46u3Qv42/8Kt57MUerrz7qYasVkRkOmp2Z3FzHHE6AEduu4s8RS6/vTH5R0RkOspmIjCD825gZnE75+d+CMBQUbekFpFsymYiADjyDHoOfTOXFq7n5ORh1m7ubXZEIiJNkd1EYEbHG84D4IaWL3H0VUvhn34fBntg1wtNDk5EpHHqdq+h/cKRZ4x+v/5X8DdLwuvD3wJJHha8BgZ2QPvc8GCb9k7YujY87Wz2wZCWoDQc5unbAsVB2LkelqwIScVy0L8dZs4P83V2hdf926FUDI/PLA7AcD/MOSQspzQU/gZ2QVoM06+7H565J8w/dxkcvBxaOmCoB3ItsPUpWPUtOPj48NyFuYeFaYqDsP2ZsJzdW+CJH4bXJ3wUZsyHbU/Dtqdgw6qwnMPfAgceFeJpmQndj0G+LYw/5GRo7QB3WHcfHHoKzF4Mxf5QPs/9IsTddSoM98FgL7TNDmXmDulwiG2wB154ADY8AEe8NZRla0dYf74V+raGbevbAk/eAYuOC5f7zntViKt/OwzsDPPMOSTEWRyE/h0wozOUOfHOsu4wtBuGesMzq5+/N8Rx1Fmw5ckQZ1qCpSeGeUrDsOP5UMa5Vti9OWw/FuIpzAif2YYHoHczDO6CY98T5uvfDo/9RyinBUeGMtu1AV74NZz8ifCZrPwWHHde2Ke2PBm2vXczPPszOOWToRzzrSH23k1hXTs3wIx5IY6BHfDcz8Mv5AHmLA2f67pfwZGnh5j7t4dt6OyCQlso/4duCsvd8GtY+NpQ1vMPD2UysBMWHhvK0eJ9t4qDsQwt7APzXh3mf2F1KPPBXSHug44J8c0+GLwU1m9JWCaE8t29GWYdFL5P/duhbQ7kW0K5D/aEfaazC3asC/M9fAsc+lvQdUrYtl0bwr6aawnr7t8O/dtg/pHw3M9g9pIwvDQIGx+EJSeEdW5dC8/+HDoWhe96oR08hb5tYfreTWGbn78v/O86NXyOAzshl4dZC8PrXS+Efa9vWyjPlpnQ/QTMXhSm37QGDjw6lHOSD+XUvz2Uy47nYM6h4TvupRBL37ZYJguh89AwbWtH+F5uWAVpGj7L3Vtg4+qwzK1PwdFnwRFnwEFHT+lhEMDc969bMa9YscJXrlw5dQt8cQ2v+4dH+N3k11w4936O6L1/6pYtIjKVTv0UvPmyvZrVzFa5+4pa47JdIwBY+Fq+/pGFfODqmXx/y6k88zdnYuWzosHecEaQbw1nZmkpnJHmW0P29jScUZlBkgtnn0kuDC8VwxnCwM4wvjgQMntxIMxTiGeZnobhAzvD/1xLWFeuBfB4JuFhvV4KyyzXQooDYdkts0biyreFs6WWWeEs2JIwzJIwn5fCGXJaDLG2zQlnf7lCODMb7AnLmbUwnPWVYy4vvzQU5hncFdbRvwNmzA3zFdrDOspn1rlC+O9pWJflwvz51rBNnoY/S0I8uQIMD4RaxHD/SFmmpTA+3xricQ/r6t8e36fhfTlGCGVrFsuuL4xvmxPO6iHGF2sgpeF4JhznSUuVX6DT3hnKsTAjTJcOh2WWhkJ8GLQdELZhuC/EU54/V4jlHD/XgZ0hxtaOGKeFsirHnWsZqV16Gs5wLQnrM4PCzLD+8udYmBGmTUth+qHd0DIj7psexpenH9oNsw4McZXLLj6xr7JveinMB1WxF0K8fVvD9ubbYXBn+CyLA/EzL4ay9XRkPygNhXkrnwcj+0x5H8nF28CXP+vi4EiZ5lvD8ltmhTPjmfPD+1xLKO+ejSNlUxoM+3hxINSoBnbAzAXhTL40DO1zwvYNxX7AXEtVrdHiZ7c7DE8KYduHdoftyRXC+OJAqO2U96XW2WEb3Ue2pTgwUpsvxNqVJWH6nhdDTWK4P3xfyvs8hHXl20MMpeGR74qXRo4vlgvjWw/Y50NeLaoRRO/75n384qmtfOxNy7j0bVNf9RIRaaaJagTZ7Swe42vvez0A/3Lf86zd3NPkaEREGkeJIOqc2cJ1H30j/cMl3vyVe7jk5gdZu7mH/aXG5O6kEzx6091fdppS6vvN9mZFrc9jf3/E6nTfx6ZbfC/3vZ0Kahoa48b71/HnNz9Yed+SS2jJJ6EJ2aG1kNCs76G7UyyFlbe15EhTp+RO/1AJj+Nb8zkSg1zVU9dyibGld6jyfu7MFgwYKoUf0Q0VU9pbcuzqH2Z2e4F8kpBPjMRgOHUGhku05hNacuG8YbCYMlRKaS/kMINtu4eYN7MVxymlTmJGKXVyiZGPcaQOiYGZhSZPg1LJGSqlDAyndLTlKabOcCllqJhSyCXMas2TxFMVw+gZGKaYhm1sb0kYLjr5nOEOxTTEk3o4UKbulEsgdRgoliqf5frt/Rx8QBtDJSeXhGWn7vQNlSoHgdZCrhJ7IZfQMzCMO8xuL1BKnb6hIkOllFmtBQaLJdLUaW/J0ZrPUUrDdg2XUvKJkc8lWFxO+XMMnxc4TurlpnmvxFtKnfZCjm19QxzQXqiUferOpl0DHNjRhsfpSym05AwHEhv53KteVl6nKZX4hoops1rzFNOUiQ4D1cupMXaP5iuWUnYPlpg/q4WSO6WUSjmPncc97KO5xOgdCO3pHW15SqmHbjkzdg2EPpXEjHmzWjCMwWKJUurkk6SyzyXJyD5USp2ZrXmGSykQ9tFcYgwMlxgqpvQOFVk4u42WfELqHvavUtg3W/Lhs0x95Ds2VErZ0TeEWVxW3Ij2lhy9g0UGiykHdrRSSp1i6hRLKaXUKeQTCrkkLDeXVPYPCN+xfBK2L3VnsJhy8AHtfPDkQ/mT33nVRB/IBJ+HOosn7ZwTlnLOCUu57+mt3P/MNnb2D1OqysjDqYeda4IvQD3lEsM9fJETCztw31CpcvBsb0nIJ2EHBuJB0ukZGKa7Z5CueTND33XqtOQTCokxMJySJGHZw0UnlzOKpZTUw5e0rZCrHDgAcmYUU6eQC/837RpgQUcrhSQhSYw0dQr5kAyGY+JKYr9tGg9+7uGAmJiRJEb/cInZbXkKuRB/+QtbfXxqb8kxOBxiSN3JJ2H9BmDhAGdALh4AygfbfBIODvlcwsBwiSMP6qBzZguFnFXOrksplNI0JNJYxuVkNlQMiQpg91CJxGBGSx4zGBhOK/Pt7B8mnzMSK29PoZJEIRwwjJgICQevclKEkHjTmOxjNyb5nLF7sFRZbnX5VyexcqItn6SMKrmql2ZG+XhT3mf6h0sc0F6oeeCeKEFMdD400XwbdvRzYNOgI3AAAAejSURBVEcr+SRsf5q+NOby/KlDSz6hvZDDcfpiWaQOfUNFOme00JpPGCym7OwPSaGQM3JJQikmuNSJB3QfOfDmE4yw75XSNOzPSThR2NwzwMzWPGnqIycuhOnKB2uzsM+UP8s5MwqVfb/6hKatkGP3YAkz4kmBVU60dg+VKvGG6Ue2v3+4SGs+x46+IRZ0tLK1d4jZ7QWWds6YoNT3nhLBOE46bB4nHaZbVIvIK5/6CEREMk6JQEQk45QIREQyTolARCTjlAhERDJOiUBEJOOUCEREMk6JQEQk4/a7W0yYWTfw3F7OPh/YMoXhTJXpGhdM39gU155RXHvmlRjXoe6+oNaI/S4R7AszWznevTaaabrGBdM3NsW1ZxTXnslaXGoaEhHJOCUCEZGMy1oiuKrZAYxjusYF0zc2xbVnFNeeyVRcmeojEBGRl8pajUBERMZQIhARybjMJAIzO93MHjeztWZ2SYPXvdTM7jSzR8zsYTO7KA6/zMw2mNnq+Hdm1Tyfi7E+bmZvrWNsz5rZQ3H9K+OwuWZ2h5k9Gf93xuFmZlfEuB40s9fXKaYjq8pktZntMrOLm1FeZnaNmW02szVVw/a4fMzsD+P0T5rZH9Ypri+b2WNx3beY2Zw4vMvM+qvK7cqqed4QP/+1MfZ9evTeOHHt8ec21d/XceL6blVMz5rZ6ji8keU13rGhsftY+aHmr+Q/IAc8BRwGtAC/AY5u4PoXAa+PrzuAJ4CjgcuAz9aY/ugYYyuwLMaeq1NszwLzxwz7O+CS+PoS4G/j6zOB2wlP5zsJ+GWDPrsXgUObUV7AbwOvB9bsbfkAc4Gn4//O+LqzDnG9BcjH139bFVdX9XRjlvOrGKvF2M+oQ1x79LnV4/taK64x4/8e+HwTymu8Y0ND97Gs1AhOBNa6+9PuPgT8K3B2o1bu7hvd/YH4ugd4FFg8wSxnA//q7oPu/gywlrANjXI28J34+jvAO6uGX+vBfcAcM1tU51h+D3jK3Sf6NXndysvd7wG21VjfnpTPW4E73H2bu28H7gBOn+q43P3H7l6Mb+8Dlky0jBjbbHe/z8PR5NqqbZmyuCYw3uc25d/XieKKZ/XnADdMtIw6ldd4x4aG7mNZSQSLgXVV79cz8YG4bsysCzge+GUc9IlYxbumXP2jsfE68GMzW2VmF8RhB7n7xvj6ReCgJsRVdh6jv6DNLi/Y8/JpRrn9EeHMsWyZmf3azO42szfFYYtjLI2Ia08+t0aX15uATe7+ZNWwhpfXmGNDQ/exrCSCacHMZgE3Axe7+y7gG8CrgOXARkL1tNFOdffXA2cAF5rZb1ePjGc+TbnG2MxagLOA78VB06G8Rmlm+YzHzC4FisB1cdBG4BB3Px74NHC9mc1uYEjT7nMb472MPtloeHnVODZUNGIfy0oi2AAsrXq/JA5rGDMrED7o69z93wDcfZO7l9w9Bb7JSHNGw+J19w3x/2bglhjDpnKTT/y/udFxRWcAD7j7phhj08sr2tPyaVh8ZvZh4O3A++MBhNj0sjW+XkVofz8ixlDdfFSXuPbic2tkeeWB/w58tyrehpZXrWMDDd7HspII7gcON7Nl8SzzPODWRq08tkFeDTzq7l+pGl7dvv4HQPmKhluB88ys1cyWAYcTOqmmOq6ZZtZRfk3obFwT11++6uAPge9XxfWheOXCScDOquprPYw6U2t2eVXZ0/L5EfAWM+uMzSJvicOmlJmdDvw5cJa791UNX2Bmufj6MEL5PB1j22VmJ8V99ENV2zKVce3p59bI7+ubgcfcvdLk08jyGu/YQKP3sX3p8d6f/gi97U8QsvulDV73qYSq3YPA6vh3JvDPwENx+K3Aoqp5Lo2xPs4+XpkwQVyHEa7I+A3wcLlcgHnAfwJPAj8B5sbhBnwtxvUQsKKOZTYT2AocUDWs4eVFSEQbgWFCu+tH9qZ8CG32a+Pf+XWKay2hnbi8j10Zp31X/HxXAw8A76hazgrCgfkp4KvEuw1McVx7/LlN9fe1Vlxx+LeBPxkzbSPLa7xjQ0P3Md1iQkQk47LSNCQiIuNQIhARyTglAhGRjFMiEBHJOCUCEZGMUyIQGcPMSjb67qdTdrdaC3e2XPPyU4o0Tr7ZAYhMQ/3uvrzZQYg0imoEIpNk4Z71f2fhfvS/MrNXx+FdZvZf8aZq/2lmh8ThB1l4LsBv4t9vxUXlzOybFu4//2Mza2/aRomgRCBSS/uYpqFzq8btdPdjCb8q/Yc47B+B77j76wg3ersiDr8CuNvdjyPcC//hOPxw4Gvufgywg/BLVpGm0S+LRcYws153n1Vj+LPAf3P3p+ONwl5093lmtoVw24ThOHyju883s25gibsPVi2ji3Df+MPj+78ACu7+xfpvmUhtqhGI7Bkf5/WeGKx6XUJ9ddJkSgQie+bcqv/3xte/INwhE+D9wE/j6/8EPg5gZjkzO6BRQYrsCZ2JiLxUu8UHmUc/dPfyJaSdZvYg4az+vXHYnwLfMrM/A7qB8+Pwi4CrzOwjhDP/jxPugCkyraiPQGSSYh/BCnff0uxYRKaSmoZERDJONQIRkYxTjUBEJOOUCEREMk6JQEQk45QIREQyTolARCTj/j/sFueeZ6hzYQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}